import math
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from statsmodels.tsa.api import VAR

import statsmodels.api as sm
from statsmodels.tsa.stattools import grangercausalitytests


# ======================
# Paths
# ======================
BASE_DIR = Path(__file__).resolve().parent
DATA_PATH = BASE_DIR / "data" / "df_draft_1209_w.sti.csv"


# ======================
# Data loader
# ======================
@st.cache_data(show_spinner=False)
def load_data(path: Path) -> pd.DataFrame:
    if not path.exists():
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()

    df = pd.read_csv(path)

    if "time" not in df.columns:
        st.error("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).set_index("time").sort_index()

    # object â†’ numeric ì‹œë„ (ë¬¸ì ì„ì„ ëŒ€ë¹„)
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = pd.to_numeric(df[c], errors="coerce")

    return df


# ======================
# Utility
# ======================
def safe_to_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").replace([np.inf, -np.inf], np.nan)


def zscore(s: pd.Series) -> pd.Series:
    s = safe_to_numeric(s)
    mu, sd = s.mean(), s.std()
    if pd.isna(sd) or sd == 0:
        return pd.Series(np.nan, index=s.index)
    return (s - mu) / sd


def find_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    """
    return (signal_emoji, score)
    score: ğŸŸ¢0, ğŸŸ¡1, ğŸ”´2, âšªï¸(missing)=1
    """
    if series is None or series.dropna().empty or pd.isna(value):
        return "âšªï¸", 1

    series = safe_to_numeric(series).dropna()
    if series.empty:
        return "âšªï¸", 1

    q1, q2 = series.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= q2:
            return "ğŸ”´", 2
        if value <= q1:
            return "ğŸŸ¢", 0
    else:
        if value <= q1:
            return "ğŸ”´", 2
        if value >= q2:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def last_valid_z_at_or_before(df: pd.DataFrame, col: str, ts: pd.Timestamp) -> Tuple[Optional[float], Optional[pd.Timestamp]]:
    """
    ts ì‹œì  'ì´ì „/ë‹¹ì¼'ì—ì„œ colì˜ ë§ˆì§€ë§‰ ìœ íš¨ê°’ì„ ì°¾ì•„ z-score ê°’ì„ ë°˜í™˜
    returns: (z_value, used_timestamp)
    """
    if col is None or col not in df.columns:
        return None, None

    s = safe_to_numeric(df[col])
    s_upto = s.loc[:ts].dropna()
    if s_upto.empty:
        return None, None

    used_ts = s_upto.index[-1]
    z = zscore(s)  # ì „ì²´ ê¸°ê°„ ê¸°ì¤€ zscore
    zv = z.loc[used_ts] if used_ts in z.index else None
    if zv is None or pd.isna(zv):
        return None, None
    return float(zv), used_ts

def build_mmi_series(df: pd.DataFrame, lookback_days: int = 60) -> pd.Series:
    """df ì „ì²´ì— ëŒ€í•´ MMI ì‹œê³„ì—´ì„ ê³„ì‚°í•´ì„œ Seriesë¡œ ë°˜í™˜"""
    mmi_vals = []
    for ts, row in df.iterrows():
        sig = compute_risk_signals(df, row)
        mmi, _, _, _ = compute_market_mood_index(df, row, sig, lookback_days=lookback_days)
        mmi_vals.append(mmi)
    return pd.Series(mmi_vals, index=df.index, name="MMI")


def run_significance_bundle(
    df: pd.DataFrame,
    mmi_col: str = "MMI",
    ret_col: str = "ret_log_1d",
    forward_days: int = 1,
    hac_lags: int = 5,
    granger_maxlag: int = 5,
):
    """
    1) ìƒê´€(Pearson)
    2) íšŒê·€(OLS + HAC robust)
    3) Granger (MMI -> returns)
    """
    out = {}

    if mmi_col not in df.columns:
        raise ValueError(f"'{mmi_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € MMI ì‹œê³„ì—´ì„ ìƒì„±í•˜ì„¸ìš”.")
    if ret_col not in df.columns:
        raise ValueError(f"'{ret_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆ: ret_log_1d)")

    tmp = df[[mmi_col, ret_col]].copy()
    tmp[mmi_col] = pd.to_numeric(tmp[mmi_col], errors="coerce")
    tmp[ret_col] = pd.to_numeric(tmp[ret_col], errors="coerce")
    tmp = tmp.dropna()

    # ë¯¸ë˜ ìˆ˜ìµë¥ (ì„ í–‰ ê²€ì •)
    tmp["ret_fwd"] = tmp[ret_col].shift(-forward_days)
    tmp["absret_fwd"] = tmp["ret_fwd"].abs()
    tmp = tmp.dropna()

    # z-score
    tmp["MMI_z"] = (tmp[mmi_col] - tmp[mmi_col].mean()) / tmp[mmi_col].std()

    # 1) correlation
    out["corr_ret"] = float(tmp[mmi_col].corr(tmp["ret_fwd"]))
    out["corr_absret"] = float(tmp[mmi_col].corr(tmp["absret_fwd"]))

    # 2) regression HAC
    X = sm.add_constant(tmp["MMI_z"])
    y1 = tmp["ret_fwd"]
    y2 = tmp["absret_fwd"]

    res1 = sm.OLS(y1, X).fit(cov_type="HAC", cov_kwds={"maxlags": hac_lags})
    res2 = sm.OLS(y2, X).fit(cov_type="HAC", cov_kwds={"maxlags": hac_lags})

    # í‘œë¡œ ì“°ê¸° ì‰¬ìš´ ìš”ì•½
    def coef_table(res):
        coef = res.params.get("MMI_z", np.nan)
        pval = res.pvalues.get("MMI_z", np.nan)
        tval = res.tvalues.get("MMI_z", np.nan)
        return {"coef(MMI_z)": float(coef), "t": float(tval), "pvalue": float(pval)}

    out["reg_ret"] = coef_table(res1)
    out["reg_absret"] = coef_table(res2)

    # 3) Granger (MMI -> ret)
    # grangercausalitytestsëŠ” [y, x] ìˆœì„œ
    gdf = tmp[["ret_fwd", mmi_col]].dropna().rename(columns={mmi_col: "MMI"})
    g = grangercausalitytests(gdf[["ret_fwd", "MMI"]], maxlag=granger_maxlag, verbose=False)

    pvals = []
    for lag in range(1, granger_maxlag + 1):
        p = g[lag][0]["ssr_ftest"][1]
        pvals.append({"lag": lag, "pvalue": float(p)})

    out["granger_pvals"] = pd.DataFrame(pvals)

    return out


# ======================
# Risk â†’ Market Mood Index (0~100)
# ======================
def compute_risk_signals(df: pd.DataFrame, row: pd.Series) -> Dict[str, Dict]:
    """
    returns dict with per-indicator: value, signal, score, colname, note
    """
    col_oi = find_col(df, ["oi_close", "oi_close_diff", "open_interest", "oi"])
    col_funding = find_col(df, ["funding_close", "funding_rate", "funding"])
    col_liq = find_col(df, ["liq_total_usd", "liq_total_usd_diff", "liquidation_usd", "liq_usd"])
    col_taker = find_col(df, ["taker_buy_ratio", "taker_ratio"])
    col_m2 = find_col(df, ["global_m2_yoy_diff", "global_m2_yoy", "m2_yoy_diff"])

    indicators = [
        ("oi", "OI", col_oi, True),
        ("funding", "Funding", col_funding, True),
        ("liq", "Liquidation(USD)", col_liq, True),
        ("taker", "Taker Bias", col_taker, True),   # 0.5ì—ì„œ ë©€ìˆ˜ë¡ ìœ„í—˜
        ("m2", "Global M2", col_m2, False),         # ë‚®ì„ìˆ˜ë¡ ìœ„í—˜(ë°©ì–´ì ìœ¼ë¡œ)
    ]

    out = {}
    for key, label, col, higher_is_risky in indicators:
        if col is None or col not in df.columns:
            out[key] = {
                "label": label, "col": None, "value": np.nan,
                "signal": "âšªï¸", "score": 1, "note": "ì»¬ëŸ¼ ì—†ìŒ"
            }
            continue

        v = row.get(col, np.nan)

        # takerëŠ” 0.5 ê¸°ì¤€ ê±°ë¦¬ë¡œ íŒë‹¨
        if key == "taker" and not pd.isna(v):
            dist = abs(float(v) - 0.5)
            series = (safe_to_numeric(df[col]) - 0.5).abs()
            sig, sc = percentile_signal(series, dist, higher_is_risky=True)
            out[key] = {
                "label": label, "col": col, "value": float(v),
                "signal": sig, "score": sc,
                "note": f"|x-0.5|={dist:.3f}"
            }
            continue

        # m2ëŠ” 0ì´ ê²°ì¸¡í‘œì‹œì¼ ìˆ˜ë„ ìˆì–´ ë°©ì–´ ì²˜ë¦¬
        if key == "m2" and (pd.isna(v) or float(v) == 0.0):
            out[key] = {
                "label": label, "col": col, "value": float(v) if not pd.isna(v) else np.nan,
                "signal": "âšªï¸", "score": 1, "note": "0/NaN (ê²°ì¸¡ ê°€ëŠ¥)"
            }
            continue

        series = safe_to_numeric(df[col])
        sig, sc = percentile_signal(series, float(v) if not pd.isna(v) else np.nan, higher_is_risky=higher_is_risky)

        out[key] = {
            "label": label, "col": col, "value": float(v) if not pd.isna(v) else np.nan,
            "signal": sig, "score": sc, "note": ""
        }

    return out


def compute_market_mood_index(
    df: pd.DataFrame,
    row: pd.Series,
    signals: Dict[str, Dict],
    lookback_days: int = 60,
) -> Tuple[float, str, str, Dict[str, object]]:
    """
    MMI: 0~100 (ë‚®ì„ìˆ˜ë¡ Calm, ë†’ì„ìˆ˜ë¡ Too Hot)
    - base: Risk Signal ì ìˆ˜ í‰ê· (0~2) â†’ 0~100
    - bonus: (ê°€ëŠ¥í•˜ë©´) sentiment / google trendsë¥¼ lookbackìœ¼ë¡œ ë³´ì •
    - explain: ì–´ë–¤ ì»¬ëŸ¼ì´ ì‹¤ì œë¡œ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ë¦¬í¬íŠ¸(dict) ë°˜í™˜
    """
    ts = row.name if isinstance(row.name, pd.Timestamp) else pd.Timestamp(row.name)

    # 1) Base = Risk score í‰ê· 
    used_signals = {k: v for k, v in signals.items() if v.get("signal") != "âšªï¸"}
    scores = [v["score"] for v in used_signals.values()]  # 0~2
    base = float(np.mean(scores)) if scores else 1.0
    mmi_base = (base / 2.0) * 100.0

    # 2) Optional bonus (lookback)
    # ë„¤ê°€ ì–´ì œ ì •ë¦¬í•´ë‘” ì»¬ëŸ¼ëª… ìš°ì„  ë°˜ì˜
    col_sent = find_col(df, ["rd_avg_sent", "avg_sent", "sentiment"])
    col_gt = find_col(df, ["gt_btc_z14", "gtrend_btc_z14", "gt_bitcoin", "gtrend_btc"])

    bonus = 0.0
    used_inputs = []
    min_ts = ts - pd.Timedelta(days=lookback_days)

    # sentiment bonus
    if col_sent and col_sent in df.columns:
        zv, used_ts = last_valid_z_at_or_before(df, col_sent, ts)
        if used_ts is not None and used_ts >= min_ts:
            w = 6.0
            contrib = float(zv) * w
            bonus += contrib
            used_inputs.append({
                "type": "sentiment",
                "col": col_sent,
                "z": float(zv),
                "weight": w,
                "contrib": contrib,
                "used_ts": used_ts,
            })

    # attention bonus
    if col_gt and col_gt in df.columns:
        zv, used_ts = last_valid_z_at_or_before(df, col_gt, ts)
        if used_ts is not None and used_ts >= min_ts:
            w = 4.0
            contrib = float(zv) * w
            bonus += contrib
            used_inputs.append({
                "type": "attention",
                "col": col_gt,
                "z": float(zv),
                "weight": w,
                "contrib": contrib,
                "used_ts": used_ts,
            })

    mmi = float(np.clip(mmi_base + bonus, 0, 100))

    # 3) Level & description
    if mmi < 20:
        level = "Calm"
        desc = "ì¡°ìš©í•œ ë°”ë‹¤. ê³¼ì—´ ì‹ í˜¸ê°€ ê±°ì˜ ì—†ê³ , ë…¸ì´ì¦ˆ ì¥ì„¸ì¼ í™•ë¥ ì´ í½ë‹ˆë‹¤."
    elif mmi < 40:
        level = "Stable"
        desc = "ì•ˆì • êµ¬ê°„. ë ˆë²„ë¦¬ì§€/ì ë¦¼ì´ í¬ì§€ ì•Šì•„ ê¸‰ê²©í•œ í”ë“¤ë¦¼ ê°€ëŠ¥ì„±ì´ ë‚®ìŠµë‹ˆë‹¤."
    elif mmi < 60:
        level = "Warm"
        desc = "ë¯¸ì§€ê·¼í•œ ê¸´ì¥ê°. ë‹¨ê¸° ë³€ë™ì„± í™•ëŒ€ ì‹ í˜¸ê°€ ì„ì—¬ ìˆì–´ ì›ì¸(í€ë”©/ì²­ì‚°/ì ë¦¼) ì ê²€ì´ ì¢‹ì•„ìš”."
    elif mmi < 80:
        level = "Hot"
        desc = "ëœ¨ê±°ìš´ êµ¬ê°„. ë ˆë²„ë¦¬ì§€/ì ë¦¼ ì‹ í˜¸ê°€ ëŠ˜ì–´ ë³€ë™ì„± í™•ëŒ€ê°€ ì¦ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    else:
        level = "Too Hot"
        desc = "ê³¼ì—´ ê²½ë³´. ê¸‰ë³€(ì²­ì‚°/ì ë¦¼) ê°€ëŠ¥ì„±ì´ ë†’ì•„ ë ˆë²„ë¦¬ì§€/í¬ì§€ì…˜ ê´€ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."

    explain = {
        "ts": ts,
        "lookback_days": lookback_days,
        "base_avg_score(0~2)": base,
        "mmi_base(0~100)": mmi_base,
        "bonus": float(bonus),
        "final_mmi": float(mmi),
        "risk_inputs_used": [
            {
                "key": k,
                "label": v.get("label"),
                "col": v.get("col"),
                "score": v.get("score"),
                "signal": v.get("signal"),
                "note": v.get("note", ""),
            }
            for k, v in signals.items()
        ],
        "optional_inputs_used": used_inputs,
        "optional_candidates": {"sentiment_col": col_sent, "attention_col": col_gt},
    }

    return mmi, level, desc, explain


def draw_gauge(score: float, level: str):
    """
    ë°˜ì› ê²Œì´ì§€(0~100) - matplotlib
    """
    bands = [
        (0, 20, "#2E86FF"),    # Calm
        (20, 40, "#2ECC71"),   # Stable
        (40, 60, "#F1C40F"),   # Warm
        (60, 80, "#E67E22"),   # Hot
        (80, 100, "#E74C3C"),  # Too Hot
    ]

    fig, ax = plt.subplots(figsize=(9, 4.6))
    ax.set_aspect("equal")
    ax.axis("off")

    # ë°´ë“œ
    for a, b, color in bands:
        theta1 = 180 * (1 - a / 100)
        theta2 = 180 * (1 - b / 100)
        wedge = plt.matplotlib.patches.Wedge(
            (0, 0), 1.0, theta2, theta1,
            width=0.18, color=color, alpha=0.95
        )
        ax.add_patch(wedge)

    # ëˆˆê¸ˆ
    for t in range(0, 101, 10):
        ang_t = math.radians(180 * (1 - t / 100))
        x1, y1 = 0.82 * math.cos(ang_t), 0.82 * math.sin(ang_t)
        x2, y2 = 0.90 * math.cos(ang_t), 0.90 * math.sin(ang_t)
        ax.plot([x1, x2], [y1, y2], linewidth=1, color="#D0D0D0")
        if t in [0, 50, 100]:
            xt, yt = 0.68 * math.cos(ang_t), 0.68 * math.sin(ang_t)
            ax.text(xt, yt, str(t), ha="center", va="center", fontsize=11, color="#777777")

    # ë°”ëŠ˜(ê°ë„/ì¢Œí‘œ ë°˜ë“œì‹œ ì •ì˜)
    ang = math.radians(180 * (1 - score / 100))
    nx, ny = 0.74 * math.cos(ang), 0.74 * math.sin(ang)

    ax.plot([0, nx], [0, ny], linewidth=4, color="#222222", zorder=2)
    ax.add_patch(plt.matplotlib.patches.Circle((0, 0), 0.04, color="#222222", zorder=3))

    # ì¤‘ì•™ í…ìŠ¤íŠ¸ (ë°”ëŠ˜ ìœ„ë¡œ + ë°°ê²½)
    ax.text(
        0, 0.20, f"{score:.0f}",
        ha="center", va="center",
        fontsize=36, fontweight="bold", color="#111111",
        zorder=10,
        bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="none", alpha=0.92)
    )
    ax.text(
        0, 0.06, level,
        ha="center", va="center",
        fontsize=14, color="#333333",
        zorder=10,
        bbox=dict(boxstyle="round,pad=0.20", fc="white", ec="none", alpha=0.92)
    )

    ax.set_xlim(-1.05, 1.05)
    ax.set_ylim(-0.10, 1.05)
    return fig


# ======================
# VAR helpers
# ======================
def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    mean = df.mean()
    std = df.std().replace(0, np.nan)
    return (df - mean) / std


def run_var_bundle(df: pd.DataFrame, selected_cols: List[str], target: str, lag: int, horizon: int, standardize: bool):
    if len(selected_cols) < 2:
        raise ValueError("VAR ë³€ìˆ˜ëŠ” 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    if target not in selected_cols:
        raise ValueError("Targetì€ ì„ íƒëœ VAR ë³€ìˆ˜ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    data = df[selected_cols].copy()
    data = data.replace([np.inf, -np.inf], np.nan).dropna()
    if standardize:
        data = zscore_df(data).dropna()

    if data.shape[0] < max(60, lag * 10):
        raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {data.shape[0]} rows (lag={lag})")

    model = VAR(data)
    res = model.fit(lag)

    rows = []
    for x in selected_cols:
        if x == target:
            continue
        try:
            test = res.test_causality(caused=target, causing=[x], kind="f")
            rows.append({"causing(x)": x, "pvalue": float(test.pvalue), "stat": float(test.test_statistic)})
        except Exception as e:
            rows.append({"causing(x)": x, "pvalue": np.nan, "stat": np.nan, "error": str(e)})

    granger = pd.DataFrame(rows).sort_values("pvalue", na_position="last").reset_index(drop=True)

    irf = res.irf(horizon)

    fevd = res.fevd(horizon)
    decomp = np.array(fevd.decomp)  # (steps, response, impulse)
    names = list(res.names)
    t_idx = names.index(target)

    if decomp.shape[0] == horizon + 1:
        decomp_use = decomp[1:, t_idx, :]
        idx = list(range(1, horizon + 1))
    else:
        decomp_use = decomp[:, t_idx, :]
        idx = list(range(1, decomp.shape[0] + 1))

    fevd_tbl = pd.DataFrame(decomp_use * 100.0, columns=names, index=idx).round(2)
    fevd_tbl.index.name = "horizon(step)"

    return granger, irf, fevd_tbl


# ======================
# UI
# ======================
def main():
    st.set_page_config(page_title="Bittles Dashboard", page_icon="ğŸ“Š", layout="wide")

    st.markdown(
        """
        <style>
        .block-container { padding-top: 1.2rem; padding-bottom: 2.2rem; }
        h1 { margin-bottom: 0.1rem; }
        [data-testid="stMetricLabel"] { white-space: normal; font-size: 0.9rem; }
        [data-testid="stMetricValue"] { font-size: 1.55rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("ğŸ“Š Bittles Dashboard")
    st.caption("Risk Signal â†’ Market Mood â†’ VAR(Granger/IRF/FEVD)ë¡œ ì‹œì¥ ìƒíƒœë¥¼ í•´ì„í•˜ëŠ” ëŒ€ì‹œë³´ë“œ")

    df = load_data(DATA_PATH)
    if df.empty:
        return

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§  Market Mood", "ğŸ§© VAR Insight", "ğŸ§ª Significance Test"])

    # Sidebar ë‚ ì§œ (ìµœê·¼ì´ ìœ„)
    st.sidebar.header("ì„¤ì •")
    dates = sorted(pd.unique(df.index.date), reverse=True)
    sel_date = st.sidebar.selectbox("ê¸°ì¤€ ë‚ ì§œ(ìµœê·¼ì´ ìœ„)", dates, format_func=lambda d: d.strftime("%Y-%m-%d"))

    day_df = df[df.index.date == sel_date]
    row = day_df.iloc[-1] if not day_df.empty else df.iloc[-1]

    # ì´ì „ ë‚ ì§œ row
    prev_row = None
    try:
        i = dates.index(sel_date)
        if i + 1 < len(dates):
            prev_day_df = df[df.index.date == dates[i + 1]]
            prev_row = prev_day_df.iloc[-1] if not prev_day_df.empty else None
    except Exception:
        prev_row = None

    signals = compute_risk_signals(df, row)

    # -----------------------
    # TAB 1
    # -----------------------
    with tab1:
        st.subheader(f"ê¸°ì¤€ ë°ì´í„° ë‚ ì§œ: {row.name:%Y-%m-%d}")

        cols = st.columns(5, gap="large")
        order = ["oi", "funding", "liq", "taker", "m2"]

        for ui, key in zip(cols, order):
            item = signals[key]
            label, colname = item["label"], item["col"]
            v, sig = item["value"], item["signal"]

            if colname is None or pd.isna(v):
                ui.metric(label, "N/A")
                ui.caption(f"{sig} Â· {item['note']}")
                continue

            delta_txt = None
            if prev_row is not None and colname in prev_row.index:
                try:
                    pv = float(prev_row[colname])
                    if key == "m2" and (pv == 0 or float(v) == 0):
                        delta_txt = None
                    else:
                        dv = float(v) - pv
                        delta_txt = f"{dv:+.4g}"
                except Exception:
                    delta_txt = None

            val_txt = f"{float(v):.4g}" if key in ["funding", "taker", "m2"] else f"{float(v):,.4g}"
            ui.metric(label, val_txt, delta=delta_txt)

            cap = f"{sig} Â· ì»¬ëŸ¼: `{colname}`"
            if item["note"]:
                cap += f" Â· {item['note']}"
            ui.caption(cap)

        st.divider()
        score_list = [signals[k]["score"] for k in order if signals[k]["signal"] != "âšªï¸"]
        avg_score = float(np.mean(score_list)) if score_list else 1.0

        if avg_score < 0.5:
            st.success("ğŸŸ¢ ê³¼ì—´ ì‹ í˜¸ëŠ” ì•½í•©ë‹ˆë‹¤.")
        elif avg_score < 1.2:
            st.info("ğŸŸ¡ ë³€ë™ì„± í™•ëŒ€ ê°€ëŠ¥ êµ¬ê°„ì…ë‹ˆë‹¤.")
        else:
            st.warning("ğŸŸ ~ğŸ”´ ê³¼ì—´/ì ë¦¼ ì‹ í˜¸ê°€ ëŠ˜ì—ˆìŠµë‹ˆë‹¤. ë ˆë²„ë¦¬ì§€/í¬ì§€ì…˜ í¬ê¸° ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.")

        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.tail(50), use_container_width=True, height=420)

    # -----------------------
    # TAB 2
    # -----------------------
    with tab2:
        st.subheader("ğŸ§  Market Mood")
        st.caption("Risk Signal + (ê°€ëŠ¥í•˜ë©´) Google Trends / Reddit Sentiment ë³´ì •ìœ¼ë¡œ 0~100 ì§€ìˆ˜ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")

        mmi, level, desc, explain = compute_market_mood_index(df, row, signals, lookback_days=60)

        left, right = st.columns([1.25, 1], gap="large")

        with left:
            fig = draw_gauge(mmi, level)
            st.pyplot(fig, clear_figure=True)

        with right:
            st.markdown(
                f"""
                <div style="border:1px solid #E8E8E8; border-radius:14px; padding:16px;">
                  <div style="display:flex; justify-content:space-between; align-items:center;">
                    <div style="font-size:18px; font-weight:700;">í˜„ì¬ ì§€ìˆ˜</div>
                    <div style="background:#F4F6FA; border-radius:999px; padding:6px 12px; font-weight:700;">
                      {level} Â· {mmi:.0f}
                    </div>
                  </div>
                  <div style="margin-top:10px; color:#333; line-height:1.55;">
                    {desc}
                  </div>
                  <div style="margin-top:10px; color:#777; font-size:13px;">
                    (ì°¸ê³ ) Market MoodëŠ” ê°€ê²© ì˜ˆì¸¡ì´ ì•„ë‹ˆë¼ â€œí˜„ì¬ ì‹œì¥ì˜ êµ¬ì¡°/ì‹¬ë¦¬ ìƒíƒœâ€ ìš”ì•½ì…ë‹ˆë‹¤.
                  </div>
                </div>
                """,
                unsafe_allow_html=True
            )

            # âœ… ì—¬ê¸°! ê³¼ê±°ê°’ ê³„ì‚°ì—ì„œ â€œë¦¬í„´ê°’ 4ê°œâ€ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            def get_past_value(days: int) -> Optional[float]:
                ts = row.name - pd.Timedelta(days=days)
                past = df.loc[:ts]
                if past.empty:
                    return None
                past_row = past.iloc[-1]
                past_signals = compute_risk_signals(df, past_row)
                val, _, _, _ = compute_market_mood_index(df, past_row, past_signals, lookback_days=60)
                return float(val)

            p1, p7, p30, p90 = get_past_value(1), get_past_value(7), get_past_value(30), get_past_value(90)

            st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)
            st.markdown(
                "<div style='border:1px solid #E8E8E8; border-radius:14px; padding:16px;'>"
                "<div style='font-size:16px; font-weight:700; margin-bottom:10px;'>ê¸°ê°„ë³„ ì§€ìˆ˜</div>",
                unsafe_allow_html=True
            )
            r1, r2 = st.columns(2)
            with r1:
                st.metric("1ì¼ ì „", "N/A" if p1 is None else f"{p1:.0f}")
                st.metric("1ì£¼ ì „", "N/A" if p7 is None else f"{p7:.0f}")
            with r2:
                st.metric("1ê°œì›” ì „", "N/A" if p30 is None else f"{p30:.0f}")
                st.metric("3ê°œì›” ì „", "N/A" if p90 is None else f"{p90:.0f}")
            st.markdown("</div>", unsafe_allow_html=True)

            with st.expander("ğŸ” Market Mood ê³„ì‚° ìƒì„¸ (ì–´ë–¤ ì»¬ëŸ¼ì´ ë°˜ì˜ëëŠ”ì§€)"):
                st.markdown("### 1) Base: Risk Signal í‰ê·  â†’ 0~100")
                st.write(f"- í‰ê·  ì ìˆ˜(0~2): **{explain['base_avg_score(0~2)']:.2f}**")
                st.write(f"- Base MMI(0~100): **{explain['mmi_base(0~100)']:.1f}**")

                st.markdown("### 2) Risk Signalì— ì‹¤ì œë¡œ ì‚¬ìš©ëœ ì»¬ëŸ¼")
                st.dataframe(pd.DataFrame(explain["risk_inputs_used"]), use_container_width=True)

                st.markdown("### 3) Bonus: Sentiment / Google Trends (ìˆì„ ë•Œë§Œ)")
                st.markdown(
                    """
                **ì™œ Bonusë¥¼ ì“°ë‚˜?**  
                í–‰ë™ ë°ì´í„°(OI/ì²­ì‚°/í€ë”©)ê°€ ì‹œì¥ì˜ â€˜êµ¬ì¡°â€™ë¥¼ ë³´ì—¬ì¤€ë‹¤ë©´,  
                Sentimentì™€ ê´€ì‹¬ë„ëŠ” **ê·¸ êµ¬ì¡°ì— ì‚¬ëŒë“¤ì´ ì–¼ë§ˆë‚˜ ë°˜ì‘í•˜ê³  ìˆëŠ”ì§€**ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

                **ê°€ì¤‘ì¹˜ ì„¤ê³„**
                - Sentiment Ã— 6  
                â†’ ê³µí¬Â·íƒìš•ì€ ë‹¨ê¸° ë³€ë™ì„±ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ê¸° ë•Œë¬¸
                - Google Trends Ã— 4  
                â†’ ê´€ì‹¬ ê¸‰ì¦ì€ ê³¼ì—´ì˜ ë³´ì¡° ì‹ í˜¸ (í›„í–‰ ê°€ëŠ¥ì„± ê³ ë ¤)

                âš ï¸ BonusëŠ” Baseë¥¼ ë’¤ì§‘ì§€ ì•Šê³ , **ì„¤ëª…ë ¥ë§Œ ë³´ê°•**í•©ë‹ˆë‹¤.
                """
                )
                if len(explain["optional_inputs_used"]) == 0:
                    st.info(
                        "ì´ë²ˆ ë‚ ì§œì—ëŠ” **ì‹¬ë¦¬/ê´€ì‹¬ ë³´ì •ì´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**\n\n"
                        "- í•´ë‹¹ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ê±°ë‚˜\n"
                        "- ìµœê·¼ 60ì¼ ì´ë‚´ ìœ íš¨í•œ ê°’ì´ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\n"
                        "â†’ ì´ ê²½ìš° Market MoodëŠ” **í–‰ë™ ë°ì´í„°ë§Œìœ¼ë¡œ ê³„ì‚°**ë©ë‹ˆë‹¤."
                    )
                    st.write("ğŸ” íƒì§€ëœ í›„ë³´ ì»¬ëŸ¼:", explain["optional_candidates"])
                else:
                    bonus_df = pd.DataFrame(explain["optional_inputs_used"])
                    bonus_df["used_ts"] = bonus_df["used_ts"].astype(str)
                    st.dataframe(bonus_df, use_container_width=True)

                st.markdown("### 4) ìµœì¢…")
                st.write(f"- Bonus í•©ê³„: **{explain['bonus']:+.2f}**")
                st.write(f"- ìµœì¢… MMI: **{explain['final_mmi']:.1f} ({level})**")

        st.divider()
        st.write("êµ¬ê°„ ì•ˆë‚´: ğŸ”µ Calm â†’ ğŸŸ¢ Stable â†’ ğŸŸ¡ Warm â†’ ğŸŸ  Hot â†’ ğŸ”´ Too Hot")

    # -----------------------
    # TAB 3
    # -----------------------
    with tab3:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD(í‘œ)")

        st.sidebar.header("VAR ì„¤ì •")
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        default_sel = [c for c in ["ret_log_1d", "funding_close", "taker_buy_ratio", "oi_close", "liq_total_usd"] if c in numeric_cols]
        if len(default_sel) < 2:
            default_sel = numeric_cols[:3]

        sel = st.sidebar.multiselect("VAR ë³€ìˆ˜ ì„ íƒ(2ê°œ ì´ìƒ)", numeric_cols, default=default_sel)
        target = st.sidebar.selectbox("Target(ë°˜ì‘)", sel, index=0) if sel else None
        impulse_candidates = [c for c in sel if c != target] if sel and target else []
        impulse = st.sidebar.selectbox("Impulse(ì¶©ê²©)", impulse_candidates, index=0) if impulse_candidates else None
        lag = st.sidebar.slider("VAR lag", 1, 10, 1)
        horizon = st.sidebar.slider("IRF/FEVD horizon", 5, 30, 10)
        standardize = st.sidebar.checkbox("z-score í‘œì¤€í™”", True)

        if st.button("VAR ì‹¤í–‰", type="primary"):
            try:
                with st.spinner("VAR ì í•© ì¤‘â€¦"):
                    g, irf, fevd = run_var_bundle(df, sel, target, lag, horizon, standardize)

                st.success("ì™„ë£Œ!")

                st.markdown("### 1) Granger (x â†’ target)")
                st.dataframe(g, use_container_width=True)

                st.markdown("### 2) IRF")
                if impulse and target:
                    fig = irf.plot(impulse=impulse, response=target)
                    fig.set_size_inches(9, 4)
                    fig.tight_layout()
                    st.pyplot(fig, clear_figure=True)
                else:
                    fig = irf.plot()
                    st.pyplot(fig, clear_figure=True)

                st.markdown("### 3) FEVD (target ê¸°ì¤€, %)")
                st.dataframe(fevd, use_container_width=True)

            except Exception as e:
                st.error(f"VAR ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # -----------------------
    # TAB 4
    # -----------------------
    with tab4:
        st.subheader("ğŸ§ª ìœ ì˜ì„± ê²€ì •: Market Mood â†’ Price")
        st.caption("MMIê°€ ë¯¸ë˜ ìˆ˜ìµë¥ /ë³€ë™ì„±ì„ ì„ í–‰ ì„¤ëª…í•˜ëŠ”ì§€ (ìƒê´€/íšŒê·€/HAC/Granger)ë¡œ í™•ì¸í•©ë‹ˆë‹¤.")

        # 1) MMI ì‹œê³„ì—´ ìƒì„±(ìºì‹œ ì¶”ì²œ)
        @st.cache_data(show_spinner=False)
        def get_mmi_df(_df: pd.DataFrame) -> pd.DataFrame:
            dfx = _df.copy()
            dfx["MMI"] = build_mmi_series(dfx, lookback_days=60)
            return dfx

        df2 = get_mmi_df(df)

        c1, c2, c3 = st.columns(3)
        with c1:
            ret_col = st.selectbox("ìˆ˜ìµë¥  ì»¬ëŸ¼", [c for c in df2.columns if "ret" in c.lower()], index=0)
        with c2:
            fwd = st.selectbox("ë¯¸ë˜ ì‹œì°¨ (days)", [1, 3, 7], index=0)
        with c3:
            maxlag = st.selectbox("Granger maxlag", [3, 5, 7, 10], index=1)

        if st.button("ê²€ì • ì‹¤í–‰", type="primary"):
            try:
                out = run_significance_bundle(
                    df=df2,
                    mmi_col="MMI",
                    ret_col=ret_col,
                    forward_days=int(fwd),
                    hac_lags=5,
                    granger_maxlag=int(maxlag),
                )

                st.markdown("### 1) ìƒê´€ê´€ê³„")
                st.write(f"- Corr(MMI, future return): **{out['corr_ret']:.4f}**")
                st.write(f"- Corr(MMI, future |return|): **{out['corr_absret']:.4f}**")

                st.markdown("### 2) íšŒê·€ (OLS + HAC robust)")
                reg_tbl = pd.DataFrame([
                    {"model": f"future return (t+{fwd})", **out["reg_ret"]},
                    {"model": f"future |return| (t+{fwd})", **out["reg_absret"]},
                ])
                st.dataframe(reg_tbl, use_container_width=True)

                st.markdown("### 3) Granger (MMI â†’ future return)")
                st.dataframe(out["granger_pvals"], use_container_width=True)

                best = out["granger_pvals"].sort_values("pvalue").iloc[0]
                if best["pvalue"] < 0.05:
                    st.success(f"âœ… Granger ìœ ì˜: lag={int(best['lag'])}, p={best['pvalue']:.4f} â†’ MMIê°€ ìˆ˜ìµë¥ ì„ ì„ í–‰ ì„¤ëª…í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"â„¹ï¸ Granger ìœ ì˜ ì¦ê±° ì•½í•¨: ìµœì € p={best['pvalue']:.4f} (maxlag={maxlag})")

            except Exception as e:
                st.error(f"ê²€ì • ì‹¤íŒ¨: {e}")

        with st.expander("í•´ì„ ê°€ì´ë“œ(íŒ€ ê³µìœ ìš©)"):
            st.markdown(
                """
    - **ìƒê´€**: ê°™ì´ ì›€ì§ì´ëŠ” ê²½í–¥(ì¸ê³¼ ì•„ë‹˜)
    - **íšŒê·€ p-value < 0.05**: MMIê°€ ë¯¸ë˜ ìˆ˜ìµë¥ /ë³€ë™ì„±ì„ ì„¤ëª…í•˜ëŠ” í†µê³„ì  ê·¼ê±°
    - **Granger p-value < 0.05**: MMIê°€ ìˆ˜ìµë¥ ì„ 'ì„ í–‰'í•˜ëŠ” íŒ¨í„´ì´ ìˆë‹¤ëŠ” ê·¼ê±°
    - ì¼ë°˜ì ìœ¼ë¡œ **ë°©í–¥(ìˆ˜ìµë¥ )** ë³´ë‹¤ **ìœ„í—˜(|ìˆ˜ìµë¥ |/ë³€ë™ì„±)** ìª½ì´ ë” ì˜ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
    """
            )

if __name__ == "__main__":
    main()
    