import math
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

BASE_DIR = Path(__file__).resolve().parent
DATA_PATH = BASE_DIR / "data" / "df_var_1209.csv"


# -----------------------------
# Data
# -----------------------------
@st.cache_data(show_spinner=False)
def load_data(path: Path) -> pd.DataFrame:
    """Load the CSV into a DataFrame with a datetime index."""
    if not path.exists():
        st.warning(
            "ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'data/df_var_1209.csv' ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. "
            "ìƒ˜í”Œ ë°ì´í„°ë¡œ í™”ë©´ì„ êµ¬ì„±í•©ë‹ˆë‹¤."
        )
        sample_index = pd.date_range(end=pd.Timestamp.utcnow().normalize(), periods=180, freq="D")
        return pd.DataFrame(
            {
                "ret_log_1d": [0.0002 * ((i % 11) - 5) for i in range(180)],
                "oi_close_diff": pd.Series(range(180)).mul(5e7).tolist(),
                "funding_close": [0.00003 + (i % 10) * 0.00002 for i in range(180)],
                "liq_total_usd_diff": [2e7 + (i % 12) * 1e7 for i in range(180)],
                "taker_buy_ratio": [0.5 + ((i % 14) - 7) * 0.01 for i in range(180)],
                "global_m2_yoy_diff": [0.02 if i % 7 else 0 for i in range(180)],
            },
            index=sample_index,
        )

    df = pd.read_csv(path)
    if "time" not in df.columns:
        raise ValueError("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).set_index("time").sort_index()
    return df


# -----------------------------
# Risk Signal utilities
# -----------------------------
def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    """Return an emoji signal and numeric score based on percentile thresholds.
    Scores: green=0, yellow=1, red=2. Neutral/unknown=âšªï¸(score 1)
    """
    if series.empty or (isinstance(value, float) and math.isnan(value)):
        return "âšªï¸", 1

    lower, upper = series.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= upper:
            return "ğŸ”´", 2
        if value <= lower:
            return "ğŸŸ¢", 0
    else:
        if value <= lower:
            return "ğŸ”´", 2
        if value >= upper:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def overall_risk_text(total_score: int, count: int) -> str:
    """Panic-sell prevention tone."""
    average_score = total_score / max(count, 1)
    if average_score < 0.5:
        return "ğŸŸ¢ í˜„ì¬ëŠ” êµ¬ì¡°ì  ê³¼ì—´ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. ê¸‰ë½ ì‹œì—ë„ íŒ¨ë‹‰ì…€ë³´ë‹¤ â€˜ì›ì¸(ì²­ì‚°/í€ë”©/ìœ ë™ì„±)â€™ í™•ì¸ì´ ìš°ì„ ì…ë‹ˆë‹¤."
    if average_score < 1.2:
        return "ğŸŸ¡ ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. íŒ¨ë‹‰ì…€ë³´ë‹¤ëŠ” â€˜ì²­ì‚°/í€ë”©/ì ë¦¼â€™ ìš”ì¸ì´ ìˆëŠ”ì§€ ë¨¼ì € ì ê²€í•˜ì„¸ìš”."
    if average_score < 1.8:
        return "ğŸŸ  ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì‹ í˜¸ê°€ ê´€ì¸¡ë©ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ë³€ë™ì„± í™•ëŒ€ê°€ ì¦ì•˜ë˜ êµ¬ê°„ì´ë‹ˆ í¬ì§€ì…˜ í¬ê¸°/ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    return "ğŸ”´ ë‹¨ê¸° ì¶©ê²©(ì²­ì‚°/ë ˆë²„ë¦¬ì§€) ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¬´ë¦¬í•œ ë ˆë²„ë¦¬ì§€ëŠ” í”¼í•˜ê³ , ë³€ë™ì„± í™•ëŒ€ë¥¼ ì „ì œë¡œ ëŒ€ì‘í•˜ì„¸ìš”."


def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


def build_cause_summary(signals: Dict[str, str]) -> str:
    """Build short explanation based on signal emojis."""
    red = [k for k, s in signals.items() if s == "ğŸ”´"]
    yellow = [k for k, s in signals.items() if s == "ğŸŸ¡"]
    neutral = [k for k, s in signals.items() if s == "âšªï¸"]

    desc = {
        "oi": "ë ˆë²„ë¦¬ì§€(ë¯¸ê²°ì œì•½ì •)",
        "funding": "í€ë”©(í¬ì§€ì…˜ ì ë¦¼/ê³¼ì—´)",
        "liq": "ì²­ì‚°(ê°•ì œ ë§¤ë„/ë§¤ìˆ˜ ì••ë ¥)",
        "taker": "í…Œì´ì»¤ ì ë¦¼(ê³µí¬/íƒìš•)",
        "m2": "ìœ ë™ì„±(M2)",
    }

    lines = []
    if red:
        lines.append("ğŸ”´ **ê°•í•œ ë‹¨ê¸° ì¶©ê²© ì‹ í˜¸**ê°€ ìˆìŠµë‹ˆë‹¤: " + ", ".join(desc[x] for x in red))
        lines.append("â†’ ê¸‰ë³€ êµ¬ê°„ì—ì„œëŠ” â€˜ì›ì¸ í™•ì¸(ì²­ì‚°/í€ë”©/ë ˆë²„ë¦¬ì§€)â€™ì´ ìš°ì„ ì´ê³ , ê°ì •ì  ë§¤ë§¤ëŠ” ì†ì‹¤ í™•ë¥ ì„ í‚¤ì›ë‹ˆë‹¤.")
    elif yellow:
        lines.append("ğŸŸ¡ **ë³€ë™ì„± í™•ëŒ€ ì‹ í˜¸**ê°€ ìˆìŠµë‹ˆë‹¤: " + ", ".join(desc[x] for x in yellow))
        lines.append("â†’ ë‹¹ì¼ ê¸‰ë½/ê¸‰ë“±ì€ â€˜ì ë¦¼â€™ ë•Œë¬¸ì— ê³¼ì¥ë  ìˆ˜ ìˆì–´, ì¶”ì„¸ê°€ ì•„ë‹ˆë¼ êµ¬ì¡°ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        lines.append("ğŸŸ¢ **ê³¼ì—´ ì‹ í˜¸ê°€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** ë‹¨ê¸° ë…¸ì´ì¦ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")

    if neutral:
        lines.append("âšªï¸ ë°ì´í„°ê°€ ë¶€ì¡±/ê²°ì¸¡ ê°€ëŠ¥: " + ", ".join(desc[x] for x in neutral))

    return "\n\n".join(lines)


# -----------------------------
# Pipeline tab utilities
# -----------------------------
def get_analysis_pipeline() -> Dict[str, List[str]]:
    """1210_VAR_ì‹œë²”.pyì˜ íë¦„ì„ 'ì¹´í…Œê³ ë¦¬'ë¡œ ë¬¶ì–´ ì§€ë„ í˜•íƒœë¡œ ë³´ì—¬ì£¼ê¸°."""
    return {
        "ë°ì´í„° ì¤€ë¹„": [
            "CSV ë¡œë“œ (time â†’ datetime index)",
            "ê²°ì¸¡/ì´ìƒì¹˜ ì²˜ë¦¬, ì •ë ¬",
            "ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ/ë§¤í•‘ (Risk / VAR ê³µí†µ)",
        ],
        "ì „ì²˜ë¦¬ & ì •ìƒì„±": [
            "ìˆ˜ìµë¥ /ì°¨ë¶„ ë“± ë³€í™˜(í•„ìš” ì‹œ)",
            "ì •ìƒì„± í™•ì¸(ADF Test) ë° ë³€í™˜ ê²°ì •",
        ],
        "VAR ëª¨ë¸ë§": [
            "VAR ì…ë ¥ ë°ì´í„° êµ¬ì„±(ì„ íƒ ë³€ìˆ˜ ì§‘í•©)",
            "Lag ì„ íƒ(AIC/BIC ë“±) ë° VAR ì í•©",
            "Granger ì¸ê³¼ì„± í…ŒìŠ¤íŠ¸",
        ],
        "IRF / FEVD": [
            "IRF(ì¶©ê²© ë°˜ì‘) ì‹œê°í™”",
            "FEVD(ë¶„ì‚°ë¶„í•´) í‘œë¡œ ê¸°ì—¬ë„ ì¶œë ¥",
            "ìš”ì•½ ì¸ì‚¬ì´íŠ¸ ìƒì„±(ì–´ë–¤ ìš”ì¸ì´ ì»¸ëŠ”ì§€)",
        ],
        "ëŒ€ì‹œë³´ë“œ ì¶œë ¥": [
            "Risk Signal(ğŸŸ¢ğŸŸ¡ğŸ”´) + íŒ¨ë‹‰ì…€ ë°©ì§€ ë©”ì‹œì§€",
            "VAR Insight(Granger/IRF/FEVD) ê²°ê³¼ ì œê³µ",
            "ê³µìœ (Cloud ë§í¬/README/ë°ì´í„° ê³µìœ  ì •ì±…)",
        ],
    }


def render_pipeline_visual(pipeline: Dict[str, List[str]]) -> None:
    """Graphviz ìˆìœ¼ë©´ íë¦„ë„, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ."""
    st.subheader("ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì „ì²´ ë³´ê¸°")
    st.caption("Risk Signal / VAR Insightê°€ ì–´ë–¤ ë¶„ì„ ë‹¨ê³„ë¥¼ ê±°ì³ ë§Œë“¤ì–´ì§€ëŠ”ì§€ ì„¤ëª…í•˜ëŠ” ì§€ë„ì…ë‹ˆë‹¤.")

    try:
        import graphviz  # type: ignore

        dot = graphviz.Digraph()
        dot.attr(rankdir="LR")

        dot.attr("node", shape="box", style="rounded,filled", fillcolor="lightgrey")
        categories = list(pipeline.keys())
        for c in categories:
            dot.node(c, c)

        dot.attr("node", shape="box", style="rounded,filled", fillcolor="white")
        for c, steps in pipeline.items():
            prev = c
            for i, s in enumerate(steps, start=1):
                sid = f"{c}_{i}"
                dot.node(sid, f"{i}. {s}")
                dot.edge(prev, sid)
                prev = sid

        st.graphviz_chart(dot, use_container_width=True)

    except Exception:
        st.info("â„¹ï¸ Graphvizê°€ ì—†ì–´ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. (ì›í•˜ë©´ requirements.txtì— graphviz ì¶”ê°€)")
        for c, steps in pipeline.items():
            st.markdown(f"### {c}")
            for i, s in enumerate(steps, start=1):
                st.markdown(f"- {i}. {s}")

    st.divider()
    st.subheader("ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ê³„(ì²´í¬ë¦¬ìŠ¤íŠ¸)")
    st.caption("íŒ€ ë‚´ë¶€ì—ì„œ â€˜ì–´ë””ê¹Œì§€ êµ¬í˜„/ê²€ì¦ëëŠ”ì§€â€™ í‘œì‹œìš©ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    for c, steps in pipeline.items():
        with st.expander(f"ğŸ“Œ {c}", expanded=(c == "IRF / FEVD")):
            for s in steps:
                st.checkbox(s, value=False, key=f"pipeline_{c}_{s}")


# -----------------------------
# VAR / Granger / IRF / FEVD
# -----------------------------
@dataclass
class VarOutputs:
    granger_matrix: pd.DataFrame
    granger_to_target: pd.DataFrame
    fevd_table: pd.DataFrame
    irf_fig: Optional["object"]  # matplotlib Figure (typing íšŒí”¼)


def _zscore(df: pd.DataFrame) -> pd.DataFrame:
    return (df - df.mean()) / (df.std(ddof=0).replace(0, pd.NA))


@st.cache_data(show_spinner=False)
def run_var_bundle(
    df: pd.DataFrame,
    cols: List[str],
    target: str,
    maxlags: int,
    horizon: int,
    standardize: bool,
) -> VarOutputs:
    """Run VAR and return Granger matrix/table, IRF figure, FEVD table."""
    # lazy import (Cloudì—ì„œ requirements ì—†ì„ ë•Œ ì—ëŸ¬ ë©”ì‹œì§€ ê¹”ë”í•˜ê²Œ)
    from statsmodels.tsa.api import VAR
    from statsmodels.tsa.stattools import grangercausalitytests

    import matplotlib.pyplot as plt  # noqa: F401

    x = df[cols].copy().dropna()
    if len(x) < (maxlags + 25):
        raise ValueError(f"VAR ì‹¤í–‰ì„ ìœ„í•œ ë°ì´í„° ê¸¸ì´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. dropna í›„ {len(x)}í–‰ (lag={maxlags})")

    if standardize:
        x = _zscore(x).dropna()

    model = VAR(x)
    res = model.fit(maxlags=maxlags)

    # ---- Granger Matrix (pairwise p-values) ----
    pvals = pd.DataFrame(index=cols, columns=cols, dtype=float)
    for caused in cols:
        for causing in cols:
            if caused == causing:
                pvals.loc[caused, causing] = float("nan")
                continue
            try:
                test = res.test_causality(caused=caused, causing=[causing], kind="f")
                pvals.loc[caused, causing] = float(test.pvalue)
            except Exception:
                pvals.loc[caused, causing] = float("nan")
    granger_matrix = pvals

    # ---- Granger to target (stable, based on grangercausalitytests) ----
    rows = []
    causes = [c for c in cols if c != target]
    for c in causes:
        try:
            g = grangercausalitytests(x[[target, c]], maxlag=maxlags, verbose=False)
            # ì„ íƒ lagì˜ p-value
            p = float(g[maxlags][0]["ssr_ftest"][1])
        except Exception:
            p = float("nan")
        rows.append({"cause": c, "target": target, "lag": maxlags, "p_value": p})
    granger_to_target = pd.DataFrame(rows).sort_values("p_value")

    # ---- IRF ----
    irf_fig = None
    try:
        irf = res.irf(horizon)
        fig = irf.plot(orth=False)
        if fig is not None:
            fig.suptitle("IRF (Impulse Response Functions)", fontsize=12)
            irf_fig = fig
    except Exception:
        irf_fig = None

    # ---- FEVD (last horizon summary) ----
    fevd = res.fevd(horizon)
    # horizon ë§ˆì§€ë§‰ ì‹œì ì˜ ë¶„ì‚°ë¶„í•´ (k x k)
    decomp = fevd.decomp[-1]
    fevd_table = pd.DataFrame(decomp, index=cols, columns=cols)
    fevd_table.index.name = "Explained (target)"
    fevd_table.columns.name = "Explainer (shock)"

    return VarOutputs(
        granger_matrix=granger_matrix,
        granger_to_target=granger_to_target,
        fevd_table=fevd_table,
        irf_fig=irf_fig,
    )


# -----------------------------
# App
# -----------------------------
def main() -> None:
    st.set_page_config(page_title="ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸ“Š ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ")
    st.caption("ì„ íƒí•œ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì£¼ìš” ì§€í‘œë¥¼ ì‹ í˜¸ë“±(ğŸŸ¢ğŸŸ¡ğŸ”´)ìœ¼ë¡œ í™•ì¸í•˜ê³ , VAR ê¸°ë°˜(Granger/IRF/FEVD) ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

    df = load_data(DATA_PATH)
    if df.empty:
        st.error("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    tab1, tab2, tab3 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§© VAR Insight", "ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸"])

    # -------------------------
    # Tab1: Risk Signal
    # -------------------------
    with tab1:
        st.sidebar.header("ì„¤ì •")
        unique_dates = sorted(pd.unique(df.index.date))

        selected_date = st.sidebar.selectbox(
            "ê¸°ì¤€ ë‚ ì§œ ì„ íƒ",
            options=unique_dates,
            index=len(unique_dates) - 1,
            format_func=lambda d: d.strftime("%Y-%m-%d"),
        )

        selected_df = df[df.index.date == selected_date]
        latest_row = selected_df.iloc[-1] if not selected_df.empty else df.iloc[-1]

        date_idx = unique_dates.index(selected_date)
        prev_date = unique_dates[date_idx - 1] if date_idx > 0 else None
        prev_row = None
        if prev_date is not None:
            prev_df = df[df.index.date == prev_date]
            prev_row = prev_df.iloc[-1] if not prev_df.empty else None

        st.subheader(f"ê¸°ì¤€ ë°ì´í„° ë‚ ì§œ: {latest_row.name:%Y-%m-%d %H:%M:%S}")

        with st.expander("ì»¬ëŸ¼ ëª©ë¡ ë³´ê¸°(ë¬¸ì œ í•´ê²°ìš©)"):
            st.write(list(df.columns))

        colmap: Dict[str, Optional[str]] = {
            "oi": find_column(df, ["oi_close_diff", "oi_diff", "open_interest_diff", "oi", "OI"]),
            "funding": find_column(df, ["funding_close", "funding", "funding_rate", "Funding"]),
            "liq": find_column(df, ["liq_total_usd_diff", "liquidation_usd", "liq_usd", "Liquidation"]),
            "taker": find_column(df, ["taker_buy_ratio", "taker_ratio", "Taker Buy Ratio"]),
            "m2": find_column(df, ["global_m2_yoy_diff", "m2_yoy_diff", "global_m2_yoy", "M2"]),
        }

        indicators = {
            "oi": {"description": "OI ë³€í™”ëŸ‰", "higher_is_risky": True},
            "funding": {"description": "í€ë”©ë¹„", "higher_is_risky": True},
            "liq": {"description": "ì²­ì‚°(USD)", "higher_is_risky": True},
            "taker": {"description": "í…Œì´ì»¤ ë§¤ìˆ˜ë¹„ì¤‘(ì ë¦¼)", "higher_is_risky": True},
            "m2": {"description": "ê¸€ë¡œë²Œ M2(YoY diff)", "higher_is_risky": False},
        }

        cols_ui = st.columns(len(indicators))
        total_score = 0
        used = 0
        signal_map: Dict[str, str] = {}

        for ui_col, (k, meta) in zip(cols_ui, indicators.items()):
            real_col = colmap.get(k)
            if not real_col:
                ui_col.warning(f"{meta['description']} ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                signal_map[k] = "âšªï¸"
                continue

            value = float(latest_row[real_col])

            if k == "taker":
                series = (df[real_col] - 0.5).abs()
                v = abs(value - 0.5)
                signal, score = percentile_signal(series, v, higher_is_risky=True)
                display_value = f"{value:.3f} (ì ë¦¼:{v:.3f})"

            elif k == "m2":
                series = df[real_col].replace(0, pd.NA).dropna()
                if value == 0:
                    signal, score = "âšªï¸", 1
                    display_value = f"{value:,.4g} (ê²°ì¸¡ê°€ëŠ¥)"
                else:
                    signal, score = percentile_signal(series, value, higher_is_risky=meta["higher_is_risky"])
                    display_value = f"{value:,.4g}"

            else:
                series = df[real_col]
                signal, score = percentile_signal(series, value, higher_is_risky=meta["higher_is_risky"])
                display_value = f"{value:,.4g}"

            delta_txt = "ì „ì¼: N/A"
            if prev_row is not None and real_col in prev_row.index:
                try:
                    prev_val = float(prev_row[real_col])
                    if k == "m2" and (prev_val == 0 or value == 0):
                        delta_txt = "ì „ì¼: N/A"
                    else:
                        delta_val = value - prev_val
                        if k in ["funding", "taker", "m2"]:
                            delta_txt = f"ì „ì¼ ëŒ€ë¹„ {delta_val:+.4f}"
                        else:
                            delta_txt = f"ì „ì¼ ëŒ€ë¹„ {delta_val:+,.0f}"
                except Exception:
                    delta_txt = "ì „ì¼: N/A"

            signal_map[k] = signal
            total_score += score
            used += 1

            ui_col.metric(
                label=f"{meta['description']} ({real_col})",
                value=display_value,
                delta=delta_txt,
            )
            ui_col.caption(f"ì‹ í˜¸: {signal}")

        st.divider()
        st.subheader("ì‹ í˜¸ë“± ìš”ì•½")
        st.write("ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ì¤‘ê°„ | ğŸ”´ ë†’ìŒ | âšªï¸ ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡ ê°€ëŠ¥")

        if used == 0:
            st.error("í•µì‹¬ ì§€í‘œ ì»¬ëŸ¼ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ ë§¤í•‘ í›„ë³´ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return

        st.success(overall_risk_text(total_score, used))

        st.subheader("ì˜¤ëŠ˜ì˜ ì›ì¸ ìš”ì•½(ìë™)")
        st.info(build_cause_summary(signal_map))

        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.tail(50))

    # -------------------------
    # Tab2: VAR Insight (Granger / IRF / FEVD)
    # -------------------------
    with tab2:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger ì¸ê³¼ í…ŒìŠ¤íŠ¸(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD ë¶„ì‚°ë¶„í•´(í‘œ)")

        # ì¶”ì²œ ë³€ìˆ˜ì…‹(ìˆìœ¼ë©´ ìë™ í¬í•¨)
        recommended = [
            "ret_log_1d",
            "oi_close_diff",
            "funding_close",
            "liq_total_usd_diff",
            "taker_buy_ratio",
            "sth_sopr",
            "lth_sopr",
            "sth_realized_price_usd_diff",
            "lth_realized_price_usd_diff",
            "rhodl_ratio",
            "global_m2_yoy_diff",
            "sp500_ret",
            "nasdaq_ret",
            "etf_aum_diff",
            "etf_flow_shock_pos",
            "etf_flow_shock_neg",
        ]
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        available = [c for c in recommended if c in numeric_cols]
        if "ret_log_1d" not in numeric_cols:
            st.error("CSVì— ret_log_1d ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. VAR/IRF/FEVD íƒ€ê²Ÿì„ ë°”ê¾¸ê±°ë‚˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # ì‚¬ì´ë“œë°” ì„¤ì •
        st.sidebar.header("VAR ì„¤ì •")
        default_cols = available if len(available) >= 5 else (["ret_log_1d"] + numeric_cols[:6])
        selected_cols = st.sidebar.multiselect(
            "VAR ë³€ìˆ˜ ì„ íƒ(2ê°œ ì´ìƒ)",
            options=numeric_cols,
            default=list(dict.fromkeys([c for c in default_cols if c in numeric_cols]))[:10],
        )
        target = st.sidebar.selectbox("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜", options=selected_cols if selected_cols else ["ret_log_1d"], index=0)
        maxlags = st.sidebar.slider("VAR lag", min_value=1, max_value=14, value=1)
        horizon = st.sidebar.slider("IRF/FEVD horizon", min_value=5, max_value=30, value=10)
        standardize = st.sidebar.checkbox("í‘œì¤€í™”(z-score) í›„ VAR ì í•©", value=True)

        if len(selected_cols) < 2:
            st.warning("VAR ì‹¤í–‰ì„ ìœ„í•´ ë³€ìˆ˜ 2ê°œ ì´ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()
        if target not in selected_cols:
            st.warning("íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì„ íƒëœ VAR ë³€ìˆ˜ ëª©ë¡ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()

        run_btn = st.button("VAR ì‹¤í–‰(Granger / IRF / FEVD)", type="primary")

        if run_btn:
            try:
                out = run_var_bundle(
                    df=df,
                    cols=selected_cols,
                    target=target,
                    maxlags=maxlags,
                    horizon=horizon,
                    standardize=standardize,
                )

                # --- Granger (target ì¤‘ì‹¬) ---
                st.subheader("1) Granger ì¸ê³¼ í…ŒìŠ¤íŠ¸ (íƒ€ê²Ÿ ê¸°ì¤€ p-value)")
                st.caption("p-valueê°€ ë‚®ì„ìˆ˜ë¡ â€˜cause â†’ targetâ€™ ì¸ê³¼ì„± ì‹ í˜¸ë¡œ í•´ì„í•©ë‹ˆë‹¤. (ë³´ìˆ˜ì ìœ¼ë¡œ í•´ì„ ê¶Œì¥)")
                st.dataframe(out.granger_to_target.style.format({"p_value": "{:.4f}"}), use_container_width=True)

                with st.expander("Granger p-value ì „ì²´ ë§¤íŠ¸ë¦­ìŠ¤ ë³´ê¸°(advanced)"):
                    st.dataframe(out.granger_matrix.style.format("{:.4f}"), use_container_width=True)

                st.divider()

                # --- IRF ---
                st.subheader("2) IRF (Impulse Response Functions)")
                st.caption("ê¸°ë³¸ì€ ì „ì²´ IRF. ë°œí‘œìš©ìœ¼ë¡œëŠ” â€˜impulse ì„ íƒ â†’ target ë°˜ì‘â€™ 1ê°œë§Œ ë³´ì—¬ì¤˜ë„ ì¢‹ì•„ìš”.")
                if out.irf_fig is None:
                    st.warning("IRF ê·¸ë˜í”„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ê²°ì¸¡/lag/horizon/ë³€ìˆ˜ ìˆ˜ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.)")
                else:
                    st.pyplot(out.irf_fig, clear_figure=True)

                st.divider()

                # --- FEVD ---
                st.subheader("3) FEVD ë¶„ì‚°ë¶„í•´ (ê¸°ì—¬ë„)")
                st.caption("ì„ íƒí•œ horizonì˜ â€˜ë§ˆì§€ë§‰ ìŠ¤í…â€™ ê¸°ì¤€ ê¸°ì—¬ë„ì…ë‹ˆë‹¤. (í–‰=ì„¤ëª…ë˜ëŠ” ë³€ìˆ˜, ì—´=ì¶©ê²© ì œê³µ ë³€ìˆ˜)")
                st.dataframe(out.fevd_table.style.format("{:.3f}"), use_container_width=True)

                st.info(
                    "í•´ì„ íŒ: target í–‰ì—ì„œ ê°’ì´ í° ì—´(ë³€ìˆ˜)ì´ â€˜target ë³€ë™ì„ ë§ì´ ì„¤ëª…í•˜ëŠ” shockâ€™ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )

            except ModuleNotFoundError as e:
                st.error(f"í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {e}")
                st.info("requirements.txtì— statsmodels, matplotlibë¥¼ ì¶”ê°€í•˜ê³  ì¬ë°°í¬í•˜ì„¸ìš”.")
            except Exception as e:
                st.error(f"VAR/Granger/IRF/FEVD ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                st.info("í•´ê²° íŒ: (1) ë³€ìˆ˜ ìˆ˜ë¥¼ 3~6ê°œë¡œ ì¤„ì´ê¸° (2) lag=1ë¶€í„° ì‹œì‘ (3) horizon 10~15 (4) í‘œì¤€í™” on/off ë³€ê²½")

    # -------------------------
    # Tab3: Pipeline
    # -------------------------
    with tab3:
        pipeline = get_analysis_pipeline()
        render_pipeline_visual(pipeline)
        st.divider()
        st.markdown(
            """
**ì´ íƒ­ì˜ ëª©ì **  
- íŒ€ì›/ë©˜í† ê°€ â€œRisk Signal / VAR Insightê°€ ì–´ë–¤ ë¶„ì„ ê³¼ì •ì„ í†µí•´ ë‚˜ì˜¤ëŠ”ì§€â€ë¥¼ ì¦‰ì‹œ ì´í•´í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.  
- 1210_VAR_ì‹œë²”.pyì˜ ì—°êµ¬/ì‹¤í—˜ ì½”ë“œëŠ” ìœ ì§€í•˜ë˜, ëŒ€ì‹œë³´ë“œì—ì„œëŠ” â€œê³¼ì • ì§€ë„ + ê²°ê³¼ ì¶œë ¥â€ í˜•íƒœë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
"""
        )


if __name__ == "__main__":
    main()

