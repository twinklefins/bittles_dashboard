# app.py
import math
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

from statsmodels.tsa.api import VAR
import matplotlib.pyplot as plt


# ======================
# Paths
# ======================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

# âœ… ìš°ì„ ìˆœìœ„: draft(ìµœì‹ ) -> var(êµ¬ë²„ì „) ìˆœìœ¼ë¡œ ìë™ ì„ íƒ
CANDIDATE_FILES = [
    "df_draft_1209_w.sti.csv",
    "df_var_1209.csv",
]


def resolve_data_path() -> Path:
    for fname in CANDIDATE_FILES:
        p = DATA_DIR / fname
        if p.exists():
            return p
    return DATA_DIR / CANDIDATE_FILES[0]


# ======================
# Utils
# ======================
def z(x: pd.Series) -> pd.Series:
    x = x.replace([np.inf, -np.inf], np.nan)
    mu = x.mean()
    sd = x.std()
    if sd == 0 or pd.isna(sd):
        return pd.Series(np.nan, index=x.index)
    return (x - mu) / sd


def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


# ======================
# CII (Consumer Investment Index)
# ======================
def build_cii(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë°ì´í„°ì— ìˆëŠ” ì»¬ëŸ¼ëª…ì„ ìë™ ë§¤í•‘í•´ì„œ CIIë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    - GT(ê´€ì‹¬): bitcoin / gtrend_btc_z14 ë“±
    - Sentiment: avg_sent / pos_ratio / neg_ratio / rolling_mean_neg / rolling_std_neg / count ë“±
    """
    out = df.copy()

    alias = {
        "gt_bitcoin": ["gt_bitcoin", "bitcoin", "gtrend_bitcoin", "gt_bitcoin_raw"],
        "gt_btc_z14": ["gt_btc_z14", "gtrend_btc_z14", "gt_btc_z14"],
        "rd_avg_sent": ["rd_avg_sent", "avg_sent", "reddit_avg_sent", "sent_avg"],
        "rd_pos_ratio": ["rd_pos_ratio", "pos_ratio", "sent_pos_ratio"],
        "rd_neg_ratio": ["rd_neg_ratio", "neg_ratio", "sent_neg_ratio"],
        "rd_rolling_mean_neg": ["rd_rolling_mean_neg", "rolling_mean_neg", "neg_rolling_mean"],
        "rd_rolling_std_neg": ["rd_rolling_std_neg", "rolling_std_neg", "neg_rolling_std"],
        "rd_count": ["rd_count", "count", "rd_cnt", "doc_count"],
    }

    def pick(key: str) -> Optional[str]:
        for c in alias[key]:
            if c in out.columns:
                return c
        return None

    col = {k: pick(k) for k in alias.keys()}
    missing = [k for k, v in col.items() if v is None]

    out.attrs["cii_colmap"] = col
    out.attrs["cii_missing"] = missing

    if missing:
        out["CII"] = np.nan
        return out

    out["rd_pos_minus_neg"] = out[col["rd_pos_ratio"]] - out[col["rd_neg_ratio"]]

    out["cii_attention"] = (z(out[col["gt_bitcoin"]]) + z(out[col["gt_btc_z14"]])) / 2
    out["cii_sentiment"] = (
        z(out[col["rd_avg_sent"]]) +
        z(out["rd_pos_minus_neg"]) -
        z(out[col["rd_rolling_mean_neg"]])
    ) / 3
    out["cii_volatility"] = (
        z(out[col["rd_rolling_std_neg"]]) +
        z(out[col["rd_count"]])
    ) / 2

    out["CII"] = (
        0.4 * out["cii_attention"] +
        0.4 * out["cii_sentiment"] +
        0.2 * out["cii_volatility"]
    )

    return out


# ======================
# Data loader
# ======================
@st.cache_data(show_spinner=False)
def load_data(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()

    df = pd.read_csv(path)

    if "time" not in df.columns:
        raise ValueError("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).set_index("time").sort_index()

    # ìˆ«ìí˜• ìºìŠ¤íŒ…(ë¬¸ìì—´ ìˆ«ì ëŒ€ë¹„)
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = pd.to_numeric(df[c], errors="ignore")

    df = build_cii(df)
    return df


# ======================
# Risk helpers
# ======================
def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    if series.empty or pd.isna(value):
        return "âšªï¸", 1

    series = series.replace([np.inf, -np.inf], np.nan).dropna()
    if series.empty:
        return "âšªï¸", 1

    lower, upper = series.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= upper:
            return "ğŸ”´", 2
        if value <= lower:
            return "ğŸŸ¢", 0
    else:
        if value <= lower:
            return "ğŸ”´", 2
        if value >= upper:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def overall_risk_text(total_score: int, count: int) -> str:
    avg = total_score / max(count, 1)
    if avg < 0.5:
        return "ğŸŸ¢ ê³¼ì—´ ì‹ í˜¸ëŠ” ì•½í•©ë‹ˆë‹¤. ê¸‰ë³€ êµ¬ê°„ì—ì„œë„ ê°ì •ì  ë§¤ë§¤ë³´ë‹¤ êµ¬ì¡°(ì²­ì‚°/í€ë”©/ë ˆë²„ë¦¬ì§€)ë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”."
    if avg < 1.2:
        return "ğŸŸ¡ ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. â€˜ì²­ì‚°/í€ë”©/ì ë¦¼â€™ ìš”ì¸ì„ ë¨¼ì € ì ê²€í•˜ì„¸ìš”."
    if avg < 1.8:
        return "ğŸŸ  ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì£¼ì˜ êµ¬ê°„ì…ë‹ˆë‹¤. í¬ì§€ì…˜ í¬ê¸°/ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    return "ğŸ”´ ë‹¨ê¸° ì¶©ê²© ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤. ë¬´ë¦¬í•œ ë ˆë²„ë¦¬ì§€ëŠ” í”¼í•˜ê³  ë³€ë™ì„± í™•ëŒ€ë¥¼ ì „ì œë¡œ ëŒ€ì‘í•˜ì„¸ìš”."


# ======================
# VAR helpers
# ======================
def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    std = df.std().replace(0, np.nan)
    return (df - df.mean()) / std


def run_var_bundle(
    df: pd.DataFrame,
    selected_cols: List[str],
    target: str,
    lag: int,
    horizon: int,
    standardize: bool,
) -> Dict[str, object]:
    if len(selected_cols) < 2:
        raise ValueError("VAR ë³€ìˆ˜ëŠ” 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    if target not in selected_cols:
        raise ValueError("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜ëŠ” ì„ íƒëœ VAR ë³€ìˆ˜ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    data = df[selected_cols].copy()
    data = data.replace([np.inf, -np.inf], np.nan).dropna()

    if standardize:
        data = zscore_df(data).dropna()

    if data.shape[0] < max(60, lag * 15):
        raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (í˜„ì¬ {data.shape[0]} rows) lag={lag} ê¸°ì¤€ ìµœì†Œ 60~ê¶Œì¥")

    res = VAR(data).fit(lag)

    # --- Granger table
    rows = []
    for x in selected_cols:
        if x == target:
            continue
        try:
            test = res.test_causality(caused=target, causing=[x], kind="f")
            rows.append(
                {
                    "causing(x)": x,
                    "caused(target)": target,
                    "stat(F)": float(test.test_statistic),
                    "pvalue": float(test.pvalue),
                }
            )
        except Exception as e:
            rows.append(
                {
                    "causing(x)": x,
                    "caused(target)": target,
                    "stat(F)": np.nan,
                    "pvalue": np.nan,
                    "error": str(e),
                }
            )
    granger = pd.DataFrame(rows).sort_values("pvalue", na_position="last").reset_index(drop=True)

    # --- IRF
    irf = res.irf(horizon)

    # --- FEVD (robust shape)
    fevd = res.fevd(horizon)
    decomp = np.array(fevd.decomp)  # (steps, response, impulse)

    names = list(res.names)
    t_idx = names.index(target)

    # step0 í¬í•¨ ì—¬ë¶€ ì²˜ë¦¬
    # decomp[t, response, impulse]
    if decomp.shape[0] == horizon + 1:
        decomp_use = decomp[1:, t_idx, :]  # (horizon, impulses)
        idx = list(range(1, horizon + 1))
    elif decomp.shape[0] == horizon:
        decomp_use = decomp[:, t_idx, :]
        idx = list(range(1, horizon + 1))
    else:
        # ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš°ë¼ë„ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ
        decomp_use = decomp[min(1, decomp.shape[0] - 1):, t_idx, :]
        idx = list(range(1, decomp_use.shape[0] + 1))

    fevd_tbl = pd.DataFrame(decomp_use * 100.0, columns=names, index=idx).round(2)
    fevd_tbl.index.name = "horizon(step)"

    return {
        "granger": granger,
        "irf": irf,
        "fevd_tbl": fevd_tbl,
        "rows_used": int(data.shape[0]),
        "names": names,
    }


# ======================
# UI
# ======================
def main():
    st.set_page_config(page_title="ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

    st.markdown(
        """
        <style>
        .block-container { padding-top: 1.1rem; padding-bottom: 2.2rem; }
        h1 { margin-bottom: 0.15rem; }
        [data-testid="stMetricLabel"] { white-space: normal; font-size: 0.92rem; }
        [data-testid="stMetricValue"] { font-size: 1.55rem; }
        section[data-testid="stSidebar"] .block-container { padding-top: 1.1rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("ğŸ“Š ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ")
    st.caption("Risk Signal(ì‹ í˜¸ë“±) + VAR Insight(Granger/IRF/FEVD) + Pipeline")

    data_path = resolve_data_path()
    df = load_data(data_path)

    if df.empty:
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{data_path}`\n\n`data/` í´ë”ì— CSVê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return

    # ---- Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§© VAR Insight", "ğŸ§­ Pipeline"])

    # ---- Sidebar common controls
    st.sidebar.header("ì„¤ì •")

    # âœ… ë‚ ì§œ: ìµœì‹ ì´ ìœ„ë¡œ(ë‚´ë¦¼ì°¨ìˆœ)
    unique_dates = sorted(pd.unique(df.index.date), reverse=True)
    sel_date = st.sidebar.selectbox(
        "ê¸°ì¤€ ë‚ ì§œ",
        options=unique_dates,
        index=0,
        format_func=lambda d: d.strftime("%Y-%m-%d"),
        key="base_date",
    )

    # í•´ë‹¹ ë‚ ì§œ ë§ˆì§€ë§‰ row
    day_df = df[df.index.date == sel_date]
    if day_df.empty:
        day_df = df.iloc[[-1]]
    latest_row = day_df.iloc[-1]

    # ì „ì¼ row (ë‚´ë¦¼ì°¨ìˆœ ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€: idx+1ì´ ì „ì¼)
    i = unique_dates.index(sel_date)
    prev_row = None
    if i + 1 < len(unique_dates):
        prev_date = unique_dates[i + 1]
        prev_day_df = df[df.index.date == prev_date]
        if not prev_day_df.empty:
            prev_row = prev_day_df.iloc[-1]

    # ======================
    # TAB 1: Risk Signal
    # ======================
    with tab1:
        st.subheader(f"ê¸°ì¤€ ë°ì´í„° ë‚ ì§œ: {sel_date:%Y-%m-%d}")

        with st.expander("âœ… ë°ì´í„° ë¡œë“œ ì •ë³´(ë””ë²„ê¹…)"):
            st.write("ì‚¬ìš© íŒŒì¼:", str(data_path))
            st.write("í–‰/ì—´:", df.shape)
            st.write("ì»¬ëŸ¼ ìˆ˜:", len(df.columns))

        # ì»¬ëŸ¼ ìë™ ë§¤í•‘
        colmap = {
            "oi": find_column(df, ["oi_close", "oi_close_diff", "open_interest", "oi"]),
            "funding": find_column(df, ["funding_close", "funding", "funding_rate"]),
            "liq": find_column(df, ["liq_total_usd", "liq_total_usd_diff", "liquidation_usd", "liq_usd"]),
            "taker": find_column(df, ["taker_buy_ratio", "taker_ratio"]),
            "m2": find_column(df, ["global_m2_yoy_diff", "m2_yoy_diff", "global_m2_yoy"]),
        }

        # í‘œì‹œìš© ì§€í‘œ ì •ì˜
        indicators = [
            ("oi", "OI", True),
            ("funding", "í€ë”©ë¹„", True),
            ("liq", "ì²­ì‚°(USD)", True),
            ("taker", "í…Œì´ì»¤ ë¹„ì¤‘(ì ë¦¼)", True),
            ("m2", "M2", False),
        ]

        cols = st.columns(len(indicators), gap="large")
        total_score, used = 0, 0

        for ui_col, (k, label, higher_is_risky) in zip(cols, indicators):
            real_col = colmap.get(k)
            if not real_col or real_col not in df.columns:
                ui_col.metric(label, "N/A")
                ui_col.caption("âšªï¸ ì»¬ëŸ¼ ì—†ìŒ")
                continue

            raw_val = latest_row.get(real_col, np.nan)

            # ê°’ í‘œì‹œ
            display_value = "N/A"
            extra_line = ""

            # m2: 0ì´ë©´ ê²°ì¸¡ ì·¨ê¸‰
            if k == "m2":
                if pd.isna(raw_val) or float(raw_val) == 0.0:
                    sig, sc = "âšªï¸", 1
                    display_value = "0"
                    extra_line = "0ê°’ â†’ ê²°ì¸¡ ê°€ëŠ¥"
                else:
                    sig, sc = percentile_signal(df[real_col], float(raw_val), higher_is_risky=higher_is_risky)
                    display_value = f"{float(raw_val):,.4g}"
            elif k == "taker":
                # ì ë¦¼: |x-0.5|
                if pd.isna(raw_val):
                    sig, sc = "âšªï¸", 1
                    display_value = "N/A"
                else:
                    v = abs(float(raw_val) - 0.5)
                    series = (df[real_col] - 0.5).abs()
                    sig, sc = percentile_signal(series, v, higher_is_risky=True)
                    display_value = f"{float(raw_val):.3f}"
                    extra_line = f"ì ë¦¼ |x-0.5| = {v:.3f}"
            else:
                if pd.isna(raw_val):
                    sig, sc = "âšªï¸", 1
                    display_value = "N/A"
                else:
                    sig, sc = percentile_signal(df[real_col], float(raw_val), higher_is_risky=higher_is_risky)
                    display_value = f"{float(raw_val):,.4g}"

            # ì „ì¼ ëŒ€ë¹„ delta
            delta_txt = None
            if prev_row is not None and real_col in prev_row.index:
                try:
                    pv = prev_row.get(real_col, np.nan)
                    if pd.isna(pv) or pd.isna(raw_val):
                        delta_txt = None
                    else:
                        dv = float(raw_val) - float(pv)
                        # ì†Œìˆ˜í˜•ì€ 4ìë¦¬, í° ê°’ì€ ì²œë‹¨ìœ„ êµ¬ë¶„
                        if k in ["funding", "taker", "m2"]:
                            delta_txt = f"{dv:+.4f}"
                        else:
                            delta_txt = f"{dv:+,.0f}"
                except Exception:
                    delta_txt = None

            ui_col.metric(label, display_value, delta=delta_txt)
            ui_col.caption(f"ì‹ í˜¸: {sig} Â· ì»¬ëŸ¼: `{real_col}`")
            if extra_line:
                ui_col.caption(extra_line)

            total_score += sc
            used += 1

        st.divider()
        st.subheader("ì‹ í˜¸ë“± ìš”ì•½")
        st.write("ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ì¤‘ê°„ | ğŸ”´ ë†’ìŒ | âšªï¸ ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡/ì»¬ëŸ¼ ì—†ìŒ")
        st.success(overall_risk_text(total_score, used))

        # ---- CII
        st.subheader("ğŸ“ˆ ì†Œë¹„ì íˆ¬ì ì¸ë±ìŠ¤ (CII)")
        if "CII" not in df.columns or df["CII"].dropna().empty:
            st.warning("CII ê³„ì‚° ë¶ˆê°€ (í•„ìš” ì»¬ëŸ¼ ë¶€ì¡±)")
            with st.expander("CII ë””ë²„ê¹… ì •ë³´"):
                st.write("missing:", df.attrs.get("cii_missing"))
                st.write("colmap:", df.attrs.get("cii_colmap"))
        else:
            # ê¸°ì¤€ ë‚ ì§œì˜ CII ë§ˆì§€ë§‰ ê°’(ê°€ëŠ¥í•˜ë©´)
            cii_val = day_df["CII"].dropna().iloc[-1] if ("CII" in day_df.columns and not day_df["CII"].dropna().empty) else df["CII"].dropna().iloc[-1]
            st.metric("CII (latest)", f"{float(cii_val):.2f}")
            st.line_chart(df["CII"].tail(200))

        # ---- Raw preview (ê°€ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ê°€ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥)"):
            st.dataframe(df.tail(50), use_container_width=True, height=520)

    # ======================
    # TAB 2: VAR Insight
    # ======================
    with tab2:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD(í‘œ)")

        st.sidebar.header("VAR ì„¤ì •")

        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]

        # ë””í´íŠ¸ í›„ë³´
        default_candidates = [c for c in [
            "ret_log_1d",
            "funding_close",
            "taker_buy_ratio",
            "oi_close",
            "oi_close_diff",
            "liq_total_usd",
            "liq_total_usd_diff",
            "global_m2_yoy_diff",
        ] if c in numeric_cols]

        sel_cols = st.sidebar.multiselect(
            "VAR ë³€ìˆ˜(2ê°œ ì´ìƒ)",
            options=numeric_cols,
            default=(default_candidates[:4] if len(default_candidates) >= 2 else numeric_cols[:3]),
        )

        target = st.sidebar.selectbox("Target(ë°˜ì‘)", options=sel_cols, index=0) if sel_cols else None

        impulse_options = [c for c in sel_cols if c != target] if sel_cols else []
        impulse = st.sidebar.selectbox("Impulse(ì¶©ê²©)", options=impulse_options, index=0) if impulse_options else None

        lag = st.sidebar.slider("lag", 1, 10, 1)
        horizon = st.sidebar.slider("horizon", 5, 30, 10)
        standardize = st.sidebar.checkbox("z-score í‘œì¤€í™”", True)
        show_full_grid = st.sidebar.checkbox("IRF ì „ì²´ ê·¸ë¦¬ë“œ(ì˜µì…˜)", False)

        run_btn = st.button("VAR ì‹¤í–‰", type="primary")

        if "var_out" not in st.session_state:
            st.session_state["var_out"] = None
            st.session_state["var_params"] = None

        if run_btn:
            try:
                with st.spinner("VAR ì í•© ì¤‘â€¦"):
                    out = run_var_bundle(
                        df=df,
                        selected_cols=sel_cols,
                        target=target,
                        lag=lag,
                        horizon=horizon,
                        standardize=standardize,
                    )
                st.session_state["var_out"] = out
                st.session_state["var_params"] = {
                    "sel_cols": sel_cols,
                    "target": target,
                    "impulse": impulse,
                    "lag": lag,
                    "horizon": horizon,
                    "standardize": standardize,
                    "show_full_grid": show_full_grid,
                }
                st.success(f"ì™„ë£Œ! (rows used: {out['rows_used']})")
            except Exception as e:
                st.session_state["var_out"] = None
                st.session_state["var_params"] = None
                st.error(f"VAR ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        out = st.session_state.get("var_out")
        params = st.session_state.get("var_params")

        if out is None:
            st.info("ì™¼ìª½ì—ì„œ ë³€ìˆ˜ ì„ íƒ í›„ **VAR ì‹¤í–‰** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            # Granger
            st.subheader("1) Granger ì¸ê³¼í…ŒìŠ¤íŠ¸ (x â†’ target)")
            st.caption("p-valueê°€ ì‘ì„ìˆ˜ë¡ xê°€ targetì„ ê·¸ëœì € ì¸ê³¼í•œë‹¤ëŠ” ê·¼ê±°ê°€ ê°•í•©ë‹ˆë‹¤(ë³´í†µ 0.05 ê¸°ì¤€).")
            st.dataframe(out["granger"], use_container_width=True, height=320)

            st.divider()

            # IRF (1ê°œ impulse -> 1ê°œ target)
            st.subheader("2) IRF (Impulse Response Functions)")
            st.caption("ë°œí‘œ/ë°ëª¨ì—ì„œëŠ” â€˜impulse 1ê°œ â†’ target 1ê°œâ€™ ê·¸ë˜í”„ê°€ ê°€ì¥ ì½ê¸° ì¢‹ìŠµë‹ˆë‹¤.")

            irf = out["irf"]
            imp = params.get("impulse")
            tgt = params.get("target")

            if imp is None or tgt is None:
                st.warning("Impulse/Target ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                fig = irf.plot(impulse=imp, response=tgt)
                fig.set_size_inches(10, 4.2)
                fig.tight_layout()
                st.pyplot(fig, clear_figure=True)

                if params.get("show_full_grid", False):
                    st.caption("ì „ì²´ ê·¸ë¦¬ë“œëŠ” ë³€ìˆ˜ê°€ ë§ìœ¼ë©´ ê²¹ì³ ë³´ì—¬ìš”(ì˜µì…˜).")
                    fig2 = irf.plot()
                    fig2.set_size_inches(12, 9)
                    fig2.tight_layout()
                    st.pyplot(fig2, clear_figure=True)

            st.divider()

            # FEVD
            st.subheader("3) FEVD ë¶„ì‚°ë¶„í•´ (target ê¸°ì¤€)")
            st.caption("ê° horizonì—ì„œ target ë³€ë™ì„ â€˜ì–´ë–¤ shock(ë³€ìˆ˜)ì´ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€(%)â€™ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            st.dataframe(out["fevd_tbl"], use_container_width=True, height=420)

    # ======================
    # TAB 3: Pipeline
    # ======================
    with tab3:
        st.subheader("ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸")
        st.markdown(
            f"""
1. **ë°ì´í„° ë¡œë“œ**
   - `data/{data_path.name}` ë¡œë“œ â†’ `time` ê¸°ì¤€ ì •ë ¬

2. **CII(ì†Œë¹„ì íˆ¬ì ì¸ë±ìŠ¤) ê³„ì‚°**
   - Google Trends(ê´€ì‹¬) + Sentiment(ì •ì„œ/ë¶€ì • ë³€ë™/ë³¼ë¥¨)
   - ì»¬ëŸ¼ëª…ì€ aliasë¡œ ìë™ ë§¤í•‘ (ì—†ìœ¼ë©´ CIIëŠ” NaN)

3. **Risk Signal**
   - OI / Funding / Liquidation / Taker / M2
   - ë¶„ìœ„ìˆ˜(33/66%) ê¸°ë°˜ ğŸŸ¢ğŸŸ¡ğŸ”´ ì‹ í˜¸

4. **VAR Insight**
   - ë³€ìˆ˜ ì„ íƒ â†’ (ì˜µì…˜) z-score â†’ VAR ì í•©
   - **Granger** í‘œ / **IRF** ê·¸ë˜í”„ / **FEVD** í‘œ
"""
        )


if __name__ == "__main__":
    main()
