import math
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

# VAR / IRF / FEVD
from statsmodels.tsa.api import VAR

import matplotlib.pyplot as plt


# ======================
# Paths
# ======================
BASE_DIR = Path(__file__).resolve().parent
DATA_PATH = BASE_DIR / "data" / "df_var_1209.csv"


# ======================
# Data loader
# ======================
@st.cache_data(show_spinner=False)
def load_data(path: Path) -> pd.DataFrame:
    """Load the CSV into a DataFrame with a datetime index."""
    if not path.exists():
        st.warning(
            "ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'data/df_var_1209.csv' ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. "
            "ìƒ˜í”Œ ë°ì´í„°ë¡œ í™”ë©´ì„ êµ¬ì„±í•©ë‹ˆë‹¤."
        )
        sample_index = pd.date_range(end=pd.Timestamp.utcnow().normalize(), periods=200, freq="D")
        return pd.DataFrame(
            {
                "ret_log_1d": np.random.normal(0, 0.02, size=len(sample_index)),
                "oi_close_diff": pd.Series(range(len(sample_index))).mul(1e8).tolist(),
                "funding_close": [0.00005 + (i % 10) * 0.00002 for i in range(len(sample_index))],
                "liq_total_usd_diff": [2e7 + (i % 12) * 1e7 for i in range(len(sample_index))],
                "taker_buy_ratio": [0.5 + ((i % 14) - 7) * 0.01 for i in range(len(sample_index))],
                "global_m2_yoy_diff": [0.03 if i % 7 else 0 for i in range(len(sample_index))],
            },
            index=sample_index,
        )

    df = pd.read_csv(path)
    if "time" not in df.columns:
        raise ValueError("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).set_index("time").sort_index()

    return df


# ======================
# Risk signal helpers
# ======================
def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    """Return an emoji signal and numeric score based on percentile thresholds.
    Scores: green=0, yellow=1, red=2. Neutral/unknown=âšªï¸(score 1)
    """
    if series.empty or (isinstance(value, float) and math.isnan(value)):
        return "âšªï¸", 1

    lower, upper = series.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= upper:
            return "ğŸ”´", 2
        if value <= lower:
            return "ğŸŸ¢", 0
    else:
        if value <= lower:
            return "ğŸ”´", 2
        if value >= upper:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def overall_risk_text(total_score: int, count: int) -> str:
    """Panic-sell prevention tone."""
    average_score = total_score / max(count, 1)
    if average_score < 0.5:
        return "ğŸŸ¢ í˜„ì¬ëŠ” êµ¬ì¡°ì  ê³¼ì—´ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. ê¸‰ë½ ì‹œì—ë„ íŒ¨ë‹‰ì…€ë³´ë‹¤ â€˜ì›ì¸(ì²­ì‚°/í€ë”©/ìœ ë™ì„±)â€™ í™•ì¸ì´ ìš°ì„ ì…ë‹ˆë‹¤."
    if average_score < 1.2:
        return "ğŸŸ¡ ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. íŒ¨ë‹‰ì…€ë³´ë‹¤ëŠ” â€˜ì²­ì‚°/í€ë”©/ì ë¦¼â€™ ìš”ì¸ì´ ìˆëŠ”ì§€ ë¨¼ì € ì ê²€í•˜ì„¸ìš”."
    if average_score < 1.8:
        return "ğŸŸ  ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì‹ í˜¸ê°€ ê´€ì¸¡ë©ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ë³€ë™ì„± í™•ëŒ€ê°€ ì¦ì•˜ë˜ êµ¬ê°„ì´ë‹ˆ í¬ì§€ì…˜ í¬ê¸°/ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    return "ğŸ”´ ë‹¨ê¸° ì¶©ê²©(ì²­ì‚°/ë ˆë²„ë¦¬ì§€) ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¬´ë¦¬í•œ ë ˆë²„ë¦¬ì§€ëŠ” í”¼í•˜ê³ , ë³€ë™ì„± í™•ëŒ€ë¥¼ ì „ì œë¡œ ëŒ€ì‘í•˜ì„¸ìš”."


def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


def build_cause_summary(signals: Dict[str, str]) -> str:
    """Build short explanation based on signal emojis."""
    red = [k for k, s in signals.items() if s == "ğŸ”´"]
    yellow = [k for k, s in signals.items() if s == "ğŸŸ¡"]
    neutral = [k for k, s in signals.items() if s == "âšªï¸"]

    desc = {
        "oi": "ë ˆë²„ë¦¬ì§€(ë¯¸ê²°ì œì•½ì •)",
        "funding": "í€ë”©(í¬ì§€ì…˜ ì ë¦¼/ê³¼ì—´)",
        "liq": "ì²­ì‚°(ê°•ì œ ë§¤ë„/ë§¤ìˆ˜ ì••ë ¥)",
        "taker": "í…Œì´ì»¤ ì ë¦¼(ê³µí¬/íƒìš•)",
        "m2": "ìœ ë™ì„±(M2)",
    }

    lines = []
    if red:
        lines.append("ğŸ”´ **ê°•í•œ ë‹¨ê¸° ì¶©ê²© ì‹ í˜¸**ê°€ ìˆìŠµë‹ˆë‹¤: " + ", ".join(desc[x] for x in red))
        lines.append("â†’ ê¸‰ë³€ êµ¬ê°„ì—ì„œëŠ” â€˜ì›ì¸ í™•ì¸(ì²­ì‚°/í€ë”©/ë ˆë²„ë¦¬ì§€)â€™ì´ ìš°ì„ ì´ê³ , ê°ì •ì  ë§¤ë§¤ëŠ” ì†ì‹¤ í™•ë¥ ì„ í‚¤ì›ë‹ˆë‹¤.")
    elif yellow:
        lines.append("ğŸŸ¡ **ë³€ë™ì„± í™•ëŒ€ ì‹ í˜¸**ê°€ ìˆìŠµë‹ˆë‹¤: " + ", ".join(desc[x] for x in yellow))
        lines.append("â†’ ë‹¹ì¼ ê¸‰ë½/ê¸‰ë“±ì€ â€˜ì ë¦¼â€™ ë•Œë¬¸ì— ê³¼ì¥ë  ìˆ˜ ìˆì–´, ì¶”ì„¸ê°€ ì•„ë‹ˆë¼ êµ¬ì¡°ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        lines.append("ğŸŸ¢ **ê³¼ì—´ ì‹ í˜¸ê°€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** ë‹¨ê¸° ë…¸ì´ì¦ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")

    if neutral:
        lines.append("âšªï¸ ë°ì´í„°ê°€ ë¶€ì¡±/ê²°ì¸¡ ê°€ëŠ¥: " + ", ".join(desc[x] for x in neutral))

    return "\n\n".join(lines)


# ======================
# VAR helpers
# ======================
def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    mean = df.mean()
    std = df.std().replace(0, np.nan)
    return (df - mean) / std


def run_var_bundle(
    df: pd.DataFrame,
    selected_cols: List[str],
    target: str,
    lag: int,
    horizon: int,
    standardize: bool,
) -> Dict[str, object]:
    """
    Fit VAR and produce:
    - granger_table: DataFrame (x -> target)
    - irf_result: IRF object
    - fevd_table_target: DataFrame (steps x impulses) for target only
    - var_results: VARResults
    """
    if len(selected_cols) < 2:
        raise ValueError("VAR ë³€ìˆ˜ëŠ” 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")

    if target not in selected_cols:
        raise ValueError("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜ëŠ” ì„ íƒëœ VAR ë³€ìˆ˜ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    data = df[selected_cols].copy()
    data = data.replace([np.inf, -np.inf], np.nan).dropna()

    if data.shape[0] < max(50, lag * 10):
        raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (í˜„ì¬ {data.shape[0]} rows). lag={lag}ë©´ ìµœì†Œ 50~100í–‰ ê¶Œì¥")

    if standardize:
        data = zscore_df(data).dropna()

    model = VAR(data)
    results = model.fit(lag)

    # ---- Granger: x -> target (p-value)
    rows = []
    for x in selected_cols:
        if x == target:
            continue
        try:
            test = results.test_causality(caused=target, causing=[x], kind="f")
            rows.append(
                {
                    "causing(x)": x,
                    "caused(target)": target,
                    "test": "F",
                    "stat": float(test.test_statistic),
                    "pvalue": float(test.pvalue),
                    "df_denom": getattr(test, "df_denom", None),
                    "df_num": getattr(test, "df_num", None),
                }
            )
        except Exception as e:
            rows.append(
                {
                    "causing(x)": x,
                    "caused(target)": target,
                    "test": "F",
                    "stat": np.nan,
                    "pvalue": np.nan,
                    "df_denom": None,
                    "df_num": None,
                    "error": str(e),
                }
            )
    granger_df = pd.DataFrame(rows).sort_values("pvalue", na_position="last").reset_index(drop=True)

    # ---- IRF
    irf = results.irf(horizon)

    # ---- FEVD to target (steps x impulses)
    fevd = results.fevd(horizon)
    # fevd.decomp shape: (horizon+1, neq, neq) or (horizon, neq, neq) depending
    decomp = np.array(fevd.decomp)

    varnames = list(results.names)
    if target not in varnames:
        raise ValueError("VAR ê²°ê³¼ì—ì„œ target ë³€ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    target_idx = varnames.index(target)

    # steps ì¶• ì²˜ë¦¬(0 í¬í•¨í•  ìˆ˜ ìˆì–´ 0 ì œì™¸í•˜ê³  1..horizonë¡œ í‘œê¸°)
    # decomp[t, response, impulse]
    # t=0ì´ í¬í•¨ë˜ë©´ ì œê±°
    steps = list(range(decomp.shape[0]))
    if 0 in steps:
        # drop step 0 for nicer display
        decomp_use = decomp[1:, :, :]
        step_labels = list(range(1, decomp.shape[0]))
    else:
        decomp_use = decomp
        step_labels = list(range(1, decomp.shape[0] + 1))

    fevd_target = decomp_use[:, target_idx, :]  # (steps, impulse_vars)
    fevd_table = pd.DataFrame(fevd_target, columns=varnames, index=step_labels)
    fevd_table = (fevd_table * 100.0).round(2)
    fevd_table.index.name = "horizon(step)"

    return {
        "granger_table": granger_df,
        "irf": irf,
        "fevd_table_target": fevd_table,
        "var_results": results,
        "var_data_rows": data.shape[0],
    }


def main() -> None:
    st.set_page_config(page_title="ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")
    # --- (ì¶”ê°€) UI ë‹¤ë“¬ê¸°ìš© CSS ---
    st.markdown(
        """
        <style>
        /* ì „ì²´ ì—¬ë°±/íƒ€ì´í¬ ì •ë¦¬ */
        .block-container { padding-top: 1.2rem; padding-bottom: 2.2rem; }
        h1 { margin-bottom: 0.25rem; }
        /* metric label ì¤„ë°”ê¿ˆ í—ˆìš© + í°íŠ¸ ì‚´ì§ ì¤„ì´ê¸° */
        [data-testid="stMetricLabel"] { white-space: normal; font-size: 0.9rem; }
        /* metric value ë„ˆë¬´ ì»¤ì„œ ë‹µë‹µí•œ ëŠë‚Œ ì™„í™” */
        [data-testid="stMetricValue"] { font-size: 1.55rem; }
        /* sidebar ê°„ê²© */
        section[data-testid="stSidebar"] .block-container { padding-top: 1.1rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.title("ğŸ“Š ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ")
    st.caption("ì„ íƒí•œ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì£¼ìš” ì§€í‘œë¥¼ ì‹ í˜¸ë“±(ğŸŸ¢ğŸŸ¡ğŸ”´) í˜•íƒœë¡œ í™•ì¸í•˜ê³ , VAR ê¸°ë°˜(Granger/IRF/FEVD) ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

    df = load_data(DATA_PATH)
    if df.empty:
        st.error("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    tab1, tab2, tab3 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§© VAR Insight", "ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸"])

    # ======================
    # Tab 1: Risk Signal
    # ======================
    with tab1:
        # ---- Sidebar: ë‚ ì§œ ì„ íƒ(YYYY-MM-DDë¡œ ê¹”ë”í•˜ê²Œ) ----
        st.sidebar.header("ì„¤ì •")
        unique_dates = sorted(pd.unique(df.index.date))

        selected_date = st.sidebar.selectbox(
            "ê¸°ì¤€ ë‚ ì§œ ì„ íƒ",
            options=unique_dates,
            index=len(unique_dates) - 1,
            format_func=lambda d: d.strftime("%Y-%m-%d"),
            key="risk_date",
        )

        selected_mask = (df.index.date == selected_date)
        selected_df = df[selected_mask] if selected_mask.any() else df
        latest_row = selected_df.iloc[-1]

        # ---- ì „ì¼ row êµ¬í•˜ê¸° ----
        date_idx = unique_dates.index(selected_date)
        prev_date = unique_dates[date_idx - 1] if date_idx > 0 else None

        if prev_date is not None:
            prev_mask = (df.index.date == prev_date)
            prev_df = df[prev_mask] if prev_mask.any() else df
            prev_row = prev_df.iloc[-1]
        else:
            prev_row = None

        st.subheader(f"ê¸°ì¤€ ë°ì´í„° ë‚ ì§œ: {latest_row.name:%Y-%m-%d %H:%M:%S}")

        with st.expander("ì»¬ëŸ¼ ëª©ë¡ ë³´ê¸°(ë¬¸ì œ í•´ê²°ìš©)"):
            st.write(list(df.columns))

        # ---- ì»¬ëŸ¼ ë§¤í•‘(ìë™ íƒì§€) ----
        colmap: Dict[str, Optional[str]] = {
            "oi": find_column(df, ["oi_close_diff", "oi_diff", "open_interest_diff", "oi", "OI"]),
            "funding": find_column(df, ["funding_close", "funding", "funding_rate", "Funding"]),
            "liq": find_column(df, ["liq_total_usd_diff", "liquidation_usd", "liq_usd", "Liquidation"]),
            "taker": find_column(df, ["taker_buy_ratio", "taker_ratio", "Taker Buy Ratio"]),
            "m2": find_column(df, ["global_m2_yoy_diff", "m2_yoy_diff", "global_m2_yoy", "M2"]),
        }

        indicators = {
            "oi": {"description": "OI ë³€í™”ëŸ‰", "higher_is_risky": True},
            "funding": {"description": "í€ë”©ë¹„", "higher_is_risky": True},
            "liq": {"description": "ì²­ì‚°(USD)", "higher_is_risky": True},
            "taker": {"description": "í…Œì´ì»¤ ë§¤ìˆ˜ë¹„ì¤‘(ì ë¦¼)", "higher_is_risky": True},
            "m2": {"description": "ê¸€ë¡œë²Œ M2(YoY diff)", "higher_is_risky": False},
        }

        cols = st.columns(len(indicators), gap="large")
        total_score = 0
        used = 0
        signal_map: Dict[str, str] = {}

        for ui_col, (k, meta) in zip(cols, indicators.items()):
            real_col = colmap.get(k)
            if not real_col:
                ui_col.warning(f"{meta['description']} ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                signal_map[k] = "âšªï¸"
                continue

            value = float(latest_row[real_col])

            # ---- ì§€í‘œë³„ ì‹ í˜¸ ê³„ì‚° ----
            extra_line = ""  # metric ì•„ë˜ì— ë¶™ì¼ ë³´ì¡° ì •ë³´(ì ë¦¼ ë“±)
            if k == "taker":
                series = (df[real_col] - 0.5).abs()
                v = abs(value - 0.5)
                signal, score = percentile_signal(series, v, higher_is_risky=True)

                # âœ… (í•µì‹¬) metric ê°’ì€ ì§§ê²Œ: 0.509 ì´ëŸ° ì‹ìœ¼ë¡œë§Œ
                display_value = f"{value:.3f}"
                extra_line = f"ì ë¦¼ |{v:.3f}| (0.5ì—ì„œ ë©€ìˆ˜ë¡ ì ë¦¼)"
            elif k == "m2":
                series = df[real_col].replace(0, pd.NA).dropna()
                if value == 0:
                    signal, score = "âšªï¸", 1
                    display_value = "N/A"
                    extra_line = "ê²°ì¸¡ ê°€ëŠ¥(0ê°’ ì²˜ë¦¬)"
                else:
                    signal, score = percentile_signal(series, value, higher_is_risky=meta["higher_is_risky"])
                    display_value = f"{value:,.4g}"
            else:
                series = df[real_col]
                signal, score = percentile_signal(series, value, higher_is_risky=meta["higher_is_risky"])
                display_value = f"{value:,.4g}"

            # ---- ì „ì¼ ëŒ€ë¹„(DoD) ê³„ì‚° ----
            delta_txt = None
            if prev_row is not None and real_col in prev_row.index:
                try:
                    prev_val = float(prev_row[real_col])
                    if k == "m2" and (prev_val == 0 or value == 0):
                        delta_txt = None
                    else:
                        delta_val = value - prev_val
                        if k in ["funding", "taker", "m2"]:
                            delta_txt = f"{delta_val:+.4f}"
                        else:
                            delta_txt = f"{delta_val:+,.0f}"
                except Exception:
                    delta_txt = None

            signal_map[k] = signal
            total_score += score
            used += 1

            # âœ… ë¼ë²¨ì€ ì§§ê²Œ(ì˜ë¦¼ ë°©ì§€) + ì‹¤ì œ ì»¬ëŸ¼ëª…ì€ captionìœ¼ë¡œ
            ui_col.metric(
                label=f"{meta['description']}",
                value=display_value,
                delta=delta_txt,
            )
            ui_col.caption(f"ì»¬ëŸ¼: `{real_col}`  Â·  ì‹ í˜¸: {signal}")
            if extra_line:
                ui_col.caption(extra_line)

        st.divider()

        st.subheader("ì‹ í˜¸ë“± ìš”ì•½")
        st.write("ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ì¤‘ê°„ | ğŸ”´ ë†’ìŒ | âšªï¸ ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡ ê°€ëŠ¥")

        if used == 0:
            st.error("í•µì‹¬ ì§€í‘œ ì»¬ëŸ¼ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ì»¬ëŸ¼ ëª©ë¡ ë³´ê¸°'ì—ì„œ ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ ë§¤í•‘ í›„ë³´ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return

        overall_text = overall_risk_text(total_score, used)
        st.success(overall_text)

        st.subheader("ì˜¤ëŠ˜ì˜ ì›ì¸ ìš”ì•½(ìë™)")
        st.info(build_cause_summary(signal_map))

        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.tail(50))

    # ======================
    # Tab 2: VAR Insight
    # ======================
    with tab2:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger ì¸ê³¼í…ŒìŠ¤íŠ¸(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD ë¶„ì‚°ë¶„í•´(í‘œ)ë¥¼ í•œ ë²ˆì— í™•ì¸í•©ë‹ˆë‹¤.")

        # ---- Sidebar: VAR controls ----
        st.sidebar.header("VAR ì„¤ì •")

        # ì¶”ì²œ í›„ë³´ ì»¬ëŸ¼ë“¤(ìˆëŠ” ê²ƒë§Œ ìë™ í¬í•¨)
        default_candidates = [c for c in ["ret_log_1d", "oi_close_diff", "funding_close", "liq_total_usd_diff", "taker_buy_ratio", "global_m2_yoy_diff"] if c in df.columns]
        all_numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]

        selected_cols = st.sidebar.multiselect(
            "VAR ë³€ìˆ˜ ì„ íƒ(2ê°œ ì´ìƒ)",
            options=all_numeric_cols,
            default=default_candidates[:4] if len(default_candidates) >= 2 else all_numeric_cols[:3],
        )

        if selected_cols:
            target = st.sidebar.selectbox("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜", options=selected_cols, index=0)
            impulse_options = [c for c in selected_cols if c != target]
            impulse_var = st.sidebar.selectbox("IRF Impulse(ì¶©ê²©) ë³€ìˆ˜", options=impulse_options, index=0 if impulse_options else 0)
        else:
            target = None
            impulse_var = None

        lag = st.sidebar.slider("VAR lag", min_value=1, max_value=10, value=1)
        horizon = st.sidebar.slider("IRF/FEVD horizon", min_value=5, max_value=30, value=10)
        standardize = st.sidebar.checkbox("í‘œì¤€í™”(z-score) í›„ VAR ì í•©", value=True)
        show_full_grid = st.sidebar.checkbox("IRF ì „ì²´ ê·¸ë¦¬ë“œ(ë³€ìˆ˜Ã—ë³€ìˆ˜)ë„ ë³´ê¸°", value=False)

        run_btn = st.button("VAR ì‹¤í–‰(Granger / IRF / FEVD)", type="primary")

        if "var_out" not in st.session_state:
            st.session_state["var_out"] = None
        if "var_params" not in st.session_state:
            st.session_state["var_params"] = None

        if run_btn:
            try:
                with st.spinner("VAR ì í•© ì¤‘â€¦ (ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”)"):
                    out = run_var_bundle(
                        df=df,
                        selected_cols=selected_cols,
                        target=target,
                        lag=lag,
                        horizon=horizon,
                        standardize=standardize,
                    )
                st.session_state["var_out"] = out
                st.session_state["var_params"] = {
                    "selected_cols": selected_cols,
                    "target": target,
                    "impulse_var": impulse_var,
                    "lag": lag,
                    "horizon": horizon,
                    "standardize": standardize,
                    "show_full_grid": show_full_grid,
                }
                st.success(f"ì™„ë£Œ! (í•™ìŠµ ë°ì´í„° rows: {out['var_data_rows']})")
            except Exception as e:
                st.error(f"VAR ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                st.session_state["var_out"] = None
                st.session_state["var_params"] = None

        # ---- Render results if exists
        out = st.session_state.get("var_out")
        params = st.session_state.get("var_params")

        if out is None:
            st.info("ì™¼ìª½ì—ì„œ ë³€ìˆ˜ ì„ íƒ í›„ **VAR ì‹¤í–‰** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            # 1) Granger table
            st.subheader("1) Granger ì¸ê³¼í…ŒìŠ¤íŠ¸ (x â†’ target)")
            st.caption("p-valueê°€ ì‘ì„ìˆ˜ë¡ â€˜xê°€ targetì„ ê·¸ëœì € ì¸ê³¼í•œë‹¤â€™ëŠ” ê·¼ê±°ê°€ ê°•í•©ë‹ˆë‹¤(í†µìƒ 0.05 ê¸°ì¤€).")
            st.dataframe(out["granger_table"], use_container_width=True)

            st.divider()

            # 2) IRF (nice: impulse 1 -> target 1)
            st.subheader("2) IRF (Impulse Response Functions)")
            st.caption("ë°ëª¨ìš©ìœ¼ë¡œëŠ” â€˜impulse 1ê°œ â†’ target 1ê°œâ€™ë§Œ í¬ê²Œ ë³´ì—¬ì£¼ëŠ” ê²Œ ê°€ì¥ ì½ê¸° ì¢‹ì•„ìš”.")

            irf = out["irf"]
            imp = params.get("impulse_var")
            tgt = params.get("target")
            h = params.get("horizon", 10)

            if imp is None or tgt is None:
                st.warning("IRFë¥¼ ìœ„í•´ impulse/target ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                # âœ… 1ê°œ impulse -> 1ê°œ target
                fig = irf.plot(impulse=imp, response=tgt)
                fig.set_size_inches(9, 4)
                fig.tight_layout()
                st.pyplot(fig, clear_figure=True)

                # (ì˜µì…˜) full grid
                if params.get("show_full_grid", False):
                    with st.expander("ì „ì²´ IRF ê·¸ë¦¬ë“œ ë³´ê¸°(ë³€ìˆ˜Ã—ë³€ìˆ˜)"):
                        fig2 = irf.plot()
                        fig2.set_size_inches(12, 10)
                        fig2.tight_layout()
                        st.pyplot(fig2, clear_figure=True)

            st.divider()

            # 3) FEVD table
            st.subheader("3) FEVD ë¶„ì‚°ë¶„í•´ (target ê¸°ì¤€)")
            st.caption("ê° horizonì—ì„œ target ë³€ë™ì„ â€˜ì–´ë–¤ shock(ë³€ìˆ˜)ì´ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€(%)â€™ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            st.dataframe(out["fevd_table_target"], use_container_width=True)

    # ======================
    # Tab 3: Pipeline visualization
    # ======================
    with tab3:
        st.subheader("ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (ì „ì²´ íë¦„ ì‹œê°í™”)")
        st.caption("íŒ€ ìš”ì²­ëŒ€ë¡œ, ëŒ€ì‹œë³´ë“œê°€ â€˜ì–´ë–¤ ìˆœì„œë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ”ì§€â€™ë¥¼ í•œ ëˆˆì— ë³´ì—¬ì£¼ëŠ” ë·°ì…ë‹ˆë‹¤.")

        st.markdown(
            """
### âœ… ì „ì²´ ë¶„ì„ ë‹¨ê³„

1. **ë°ì´í„° ë¡œë“œ**
   - `data/df_var_1209.csv` ë¡œë“œ â†’ `time` ê¸°ì¤€ ì •ë ¬

2. **Risk Signal (ì‹ í˜¸ë“±)**
   - OI / Funding / Liquidation / Taker / M2 ì§€í‘œ
   - ë¶„ìœ„ìˆ˜(33%/66%) ê¸°ë°˜ ğŸŸ¢ğŸŸ¡ğŸ”´ ì‹ í˜¸ ìƒì„±
   - ì „ì¼ ëŒ€ë¹„ ë³€í™” + ì›ì¸ ìš”ì•½(ìë™ ë©”ì‹œì§€)

3. **VAR Insight (ì¸ì‚¬ì´íŠ¸)**
   - (ì‚¬ìš©ì ì„ íƒ) ë³€ìˆ˜ 2ê°œ ì´ìƒ ì„ íƒ
   - (ì„ íƒ) z-score í‘œì¤€í™”
   - VAR(lag) ì í•©
   - **Granger**: `x â†’ target` ì¸ê³¼í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œ
   - **IRF**: (impulse 1ê°œ â†’ target 1ê°œ) ë°˜ì‘ ê·¸ë˜í”„
   - **FEVD**: target ë¶„ì‚° ë¶„í•´(%) í‘œ

---

### ğŸ§© ë°ëª¨ìš© ì¶”ì²œ ì‚¬ìš©ë²• (ë©˜í† /íŒ€ì› ë°œí‘œ ê¸°ì¤€)

- Target(ë°˜ì‘): `ret_log_1d`
- Impulse(ì¶©ê²©): `liq_total_usd_diff` ë˜ëŠ” `funding_close` ë˜ëŠ” `oi_close_diff`
- Lag: 1~2
- Horizon: 10

ğŸ‘‰ ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´ â€˜ì²­ì‚°/í€ë”©/ë ˆë²„ë¦¬ì§€ ì¶©ê²©ì´ ìˆ˜ìµë¥ ì— ë¯¸ì¹˜ëŠ” ë™í•™â€™ì„ **ê¹”ë”í•˜ê²Œ 1ì¥ ê·¸ë˜í”„ë¡œ** ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
        )


if __name__ == "__main__":
    main()
