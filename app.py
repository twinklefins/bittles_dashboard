import math
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

import matplotlib.pyplot as plt
from statsmodels.tsa.api import VAR


# ======================
# Paths
# ======================
BASE_DIR = Path(__file__).resolve().parent
DATA_PATH = BASE_DIR / "data" / "df_draft_1209_w.sti.csv"


# ======================
# Data loader
# ======================
@st.cache_data(show_spinner=False)
def load_data(path: Path) -> pd.DataFrame:
    if not path.exists():
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()

    df = pd.read_csv(path)

    if "time" not in df.columns:
        st.error("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).set_index("time").sort_index()

    # ìˆ«ìí˜• ì»¬ëŸ¼ ë‚´ inf ì œê±°
    df = df.replace([np.inf, -np.inf], np.nan)
    return df


# ======================
# Utils
# ======================
def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    """Return emoji + score (green=0, yellow=1, red=2, neutral=1)."""
    if series.empty or pd.isna(value):
        return "âšªï¸", 1

    s = series.dropna()
    if s.empty:
        return "âšªï¸", 1

    lower, upper = s.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= upper:
            return "ğŸ”´", 2
        if value <= lower:
            return "ğŸŸ¢", 0
    else:
        if value <= lower:
            return "ğŸ”´", 2
        if value >= upper:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def overall_risk_text(avg_score: float) -> str:
    if avg_score < 0.5:
        return "ğŸŸ¢ í˜„ì¬ëŠ” êµ¬ì¡°ì  ê³¼ì—´ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. ê¸‰ë½ ì‹œì—ë„ íŒ¨ë‹‰ì…€ë³´ë‹¤ â€˜ì›ì¸(ì²­ì‚°/í€ë”©/ìœ ë™ì„±)â€™ í™•ì¸ì´ ìš°ì„ ì…ë‹ˆë‹¤."
    if avg_score < 1.2:
        return "ğŸŸ¡ ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. íŒ¨ë‹‰ì…€ë³´ë‹¤ëŠ” â€˜ì²­ì‚°/í€ë”©/ì ë¦¼â€™ ìš”ì¸ì´ ìˆëŠ”ì§€ ë¨¼ì € ì ê²€í•˜ì„¸ìš”."
    if avg_score < 1.8:
        return "ğŸŸ  ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì‹ í˜¸ê°€ ê´€ì¸¡ë©ë‹ˆë‹¤. í¬ì§€ì…˜ í¬ê¸°/ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    return "ğŸ”´ ë‹¨ê¸° ì¶©ê²©(ì²­ì‚°/ë ˆë²„ë¦¬ì§€) ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¬´ë¦¬í•œ ë ˆë²„ë¦¬ì§€ëŠ” í”¼í•˜ê³  ë³€ë™ì„± í™•ëŒ€ë¥¼ ì „ì œë¡œ ëŒ€ì‘í•˜ì„¸ìš”."


def market_mood_label(avg_score: float) -> Tuple[str, str]:
    """Market Mood (ì‰¬ìš´ ë§ + ì¬ë°ŒëŠ” í†¤)"""
    if avg_score < 0.5:
        return "ğŸ”µ Calm", "ì‹œì¥ ê³¼ì—´/ì ë¦¼ ì‹ í˜¸ê°€ ë‚®ì€ í¸ì…ë‹ˆë‹¤. ë‹¨ê¸° ë³€ë™ì€ â€˜êµ¬ì¡°â€™ë³´ë‹¤ â€˜ì´ë²¤íŠ¸â€™ ìš”ì¸ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤."
    if avg_score < 1.0:
        return "ğŸŸ¢ Stable", "ì‹¬ë¦¬ì™€ ë ˆë²„ë¦¬ì§€ ì§€í‘œê°€ ë¹„êµì  ê· í˜•ì…ë‹ˆë‹¤. ê³¼ì—´ ì‹ í˜¸ëŠ” ì œí•œì ì…ë‹ˆë‹¤."
    if avg_score < 1.4:
        return "ğŸŸ¡ Warm", "ì‹œì¥ ê´€ì‹¬ì´ ì˜¬ë¼ì˜¤ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆì–´ìš”(ì ë¦¼/ì²­ì‚° ì²´í¬ ê¶Œì¥)."
    if avg_score < 1.8:
        return "ğŸŸ  Hot", "ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì‹ í˜¸ê°€ ê´€ì¸¡ë©ë‹ˆë‹¤. ë‹¨ê¸° ì¡°ì •/ë³€ë™ì„± í™•ëŒ€ ê°€ëŠ¥ì„±ì— ìœ ì˜í•˜ì„¸ìš”."
    return "ğŸ”´ Too Hot", "ê³¼ì—´ ê²½ê³  êµ¬ê°„ì…ë‹ˆë‹¤. ì²­ì‚°/ê¸‰ë³€ë™ ë¦¬ìŠ¤í¬ê°€ ì»¤ì§ˆ ìˆ˜ ìˆì–´ â€˜ê°ì • ë§¤ë§¤â€™ëŠ” íŠ¹íˆ ìœ„í—˜í•©ë‹ˆë‹¤."


def build_cause_summary(signals: Dict[str, str]) -> str:
    """Short, human-readable summary."""
    red = [k for k, s in signals.items() if s == "ğŸ”´"]
    yellow = [k for k, s in signals.items() if s == "ğŸŸ¡"]
    neutral = [k for k, s in signals.items() if s == "âšªï¸"]

    desc = {
        "oi": "ë ˆë²„ë¦¬ì§€(OI)",
        "funding": "í€ë”©(ì ë¦¼/ê³¼ì—´)",
        "liq": "ì²­ì‚°(ê°•ì œ ì²´ê²°)",
        "taker": "í…Œì´ì»¤ ì ë¦¼",
        "m2": "ìœ ë™ì„±(M2)",
    }

    lines = []
    if red:
        lines.append("ğŸ”´ **ê°•í•œ ë‹¨ê¸° ë¦¬ìŠ¤í¬ ì‹ í˜¸**: " + ", ".join(desc[x] for x in red))
        lines.append("â†’ ê¸‰ë³€ êµ¬ê°„ì—ì„œëŠ” â€˜ì›ì¸ í™•ì¸(ì²­ì‚°/í€ë”©/ë ˆë²„ë¦¬ì§€)â€™ì´ ë¨¼ì €ì´ê³ , ì¦‰í¥ ë§¤ë§¤ëŠ” ì†ì‹¤ í™•ë¥ ì„ í‚¤ì›ë‹ˆë‹¤.")
    elif yellow:
        lines.append("ğŸŸ¡ **ë³€ë™ì„± í™•ëŒ€ ì‹ í˜¸**: " + ", ".join(desc[x] for x in yellow))
        lines.append("â†’ ë‹¹ì¼ ê¸‰ë½/ê¸‰ë“±ì´ â€˜ì ë¦¼â€™ìœ¼ë¡œ ê³¼ì¥ë  ìˆ˜ ìˆì–´ ì¶”ì„¸ì¸ì§€ êµ¬ì¡°ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        lines.append("ğŸŸ¢ **ê³¼ì—´ ì‹ í˜¸ê°€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** ë‹¨ê¸° ë…¸ì´ì¦ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")

    if neutral:
        lines.append("âšªï¸ ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡ ê°€ëŠ¥: " + ", ".join(desc[x] for x in neutral))

    return "\n\n".join(lines)


# ======================
# VAR helpers
# ======================
def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    mu = df.mean()
    sd = df.std().replace(0, np.nan)
    return (df - mu) / sd


def run_var_bundle(
    df: pd.DataFrame,
    selected_cols: List[str],
    target: str,
    lag: int,
    horizon: int,
    standardize: bool,
) -> Dict[str, object]:
    if len(selected_cols) < 2:
        raise ValueError("VAR ë³€ìˆ˜ëŠ” 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    if target not in selected_cols:
        raise ValueError("íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì„ íƒëœ VAR ë³€ìˆ˜ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    data = df[selected_cols].copy()
    data = data.replace([np.inf, -np.inf], np.nan).dropna()

    if data.shape[0] < max(80, lag * 12):
        raise ValueError(f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬ {data.shape[0]} rows) lag={lag}ë©´ 80í–‰ ì´ìƒ ê¶Œì¥")

    if standardize:
        data = zscore_df(data).dropna()

    model = VAR(data)
    results = model.fit(lag)

    # Granger: x -> target
    rows = []
    for x in selected_cols:
        if x == target:
            continue
        try:
            test = results.test_causality(caused=target, causing=[x], kind="f")
            rows.append(
                {
                    "causing(x)": x,
                    "caused(target)": target,
                    "stat(F)": float(test.test_statistic),
                    "pvalue": float(test.pvalue),
                }
            )
        except Exception as e:
            rows.append({"causing(x)": x, "caused(target)": target, "stat(F)": np.nan, "pvalue": np.nan, "error": str(e)})

    granger_df = pd.DataFrame(rows).sort_values("pvalue", na_position="last").reset_index(drop=True)

    # IRF / FEVD
    irf = results.irf(horizon)
    fevd = results.fevd(horizon)

    varnames = list(results.names)
    t_idx = varnames.index(target)

    decomp = np.array(fevd.decomp)  # (steps, response, impulse)
    # step 0 ì œê±° (í‘œ ë³´ê¸° ì¢‹ê²Œ)
    if decomp.shape[0] >= 2:
        decomp = decomp[1:, :, :]
        step_index = list(range(1, decomp.shape[0] + 1))
    else:
        step_index = list(range(decomp.shape[0]))

    fevd_target = decomp[:, t_idx, :]  # (steps, impulse)
    fevd_table = pd.DataFrame(fevd_target * 100.0, columns=varnames, index=step_index).round(2)
    fevd_table.index.name = "horizon(step)"

    return {
        "granger_table": granger_df,
        "irf": irf,
        "fevd_table_target": fevd_table,
        "var_results": results,
        "var_rows": data.shape[0],
        "var_names": varnames,
    }


# ======================
# App
# ======================
def main() -> None:
    st.set_page_config(page_title="Bittles Dashboard", page_icon="ğŸ“Š", layout="wide")

    # UI polish: metric ë¼ë²¨ ì¤„ë°”ê¿ˆ/ì˜ë¦¼ ë°©ì§€
    st.markdown(
        """
        <style>
        .block-container { padding-top: 1.0rem; padding-bottom: 2rem; }
        [data-testid="stMetricLabel"] { white-space: normal; font-size: 0.9rem; }
        [data-testid="stMetricValue"] { font-size: 1.55rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("ğŸ“Š Bittles Dashboard")
    st.caption("Risk Signal â†’ Market Mood â†’ VAR(Granger/IRF/FEVD)ë¡œ â€˜ì‹œì¥ ìƒíƒœâ€™ë¥¼ í•´ì„í•˜ëŠ” ëŒ€ì‹œë³´ë“œ")

    df = load_data(DATA_PATH)
    if df.empty:
        st.stop()

    tab1, tab2, tab3 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§  Market Mood", "ğŸ§© VAR Insight"])

    # ======================
    # Tab 1: Risk Signal
    # ======================
    with tab1:
        st.sidebar.header("ì„¤ì •")

        # âœ… ë‚ ì§œ: ìµœê·¼ ë‚ ì§œê°€ ë§¨ ìœ„ (ë‚´ë¦¼ì°¨ìˆœ)
        unique_dates = sorted(pd.unique(df.index.date), reverse=True)

        selected_date = st.sidebar.selectbox(
            "ê¸°ì¤€ ë‚ ì§œ(ìµœê·¼ì´ ìœ„)",
            options=unique_dates,
            index=0,
            format_func=lambda d: d.strftime("%Y-%m-%d"),
            key="risk_date",
        )

        selected_df = df[df.index.date == selected_date]
        if selected_df.empty:
            st.error("ì„ íƒí•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        today = selected_df.iloc[-1]

        # ì „ì¼ (unique_datesëŠ” ë‚´ë¦¼ì°¨ìˆœì´ë¯€ë¡œ +1ì´ ì „ì¼)
        idx = unique_dates.index(selected_date)
        prev_date = unique_dates[idx + 1] if idx < len(unique_dates) - 1 else None
        prev_row = df[df.index.date == prev_date].iloc[-1] if prev_date else None

        st.subheader(f"ê¸°ì¤€ ì‹œì : {today.name:%Y-%m-%d %H:%M:%S}")

        # ì»¬ëŸ¼ ë§¤í•‘(ìë™)
        colmap: Dict[str, Optional[str]] = {
            "oi": find_column(df, ["oi_close_diff", "oi_diff", "open_interest_diff", "open_interest", "oi"]),
            "funding": find_column(df, ["funding_close", "funding", "funding_rate"]),
            "liq": find_column(df, ["liq_total_usd_diff", "liquidation_usd", "liq_usd", "liq_total_usd"]),
            "taker": find_column(df, ["taker_buy_ratio", "taker_ratio"]),
            "m2": find_column(df, ["global_m2_yoy_diff", "m2_yoy_diff", "global_m2_yoy", "m2_yoy"]),
        }

        indicators = {
            "oi": {"title": "OI ë³€í™”", "higher_is_risky": True},
            "funding": {"title": "í€ë”©ë¹„", "higher_is_risky": True},
            "liq": {"title": "ì²­ì‚°(USD)", "higher_is_risky": True},
            "taker": {"title": "í…Œì´ì»¤ ë¹„ì¤‘", "higher_is_risky": True},
            "m2": {"title": "M2(ìœ ë™ì„±)", "higher_is_risky": False},
        }

        cols = st.columns(len(indicators), gap="large")

        total_score, used = 0, 0
        signal_map: Dict[str, str] = {}

        for ui_col, (k, meta) in zip(cols, indicators.items()):
            real_col = colmap.get(k)
            if not real_col:
                ui_col.metric(meta["title"], "N/A")
                ui_col.caption("âšªï¸ (ì»¬ëŸ¼ ì—†ìŒ)")
                signal_map[k] = "âšªï¸"
                continue

            value = today.get(real_col, np.nan)
            if pd.isna(value):
                ui_col.metric(meta["title"], "N/A")
                ui_col.caption(f"âšªï¸ `{real_col}` ê²°ì¸¡")
                signal_map[k] = "âšªï¸"
                continue

            value = float(value)

            # takerëŠ” 0.5ì—ì„œ ë©€ìˆ˜ë¡ ì ë¦¼(ë¦¬ìŠ¤í¬)ë¡œ ë³´ê¸° ì¢‹ìŒ
            extra_line = ""
            if k == "taker":
                series = (df[real_col] - 0.5).abs()
                v = abs(value - 0.5)
                signal, score = percentile_signal(series, v, higher_is_risky=True)
                display_value = f"{value:.3f}"
                extra_line = f"ì ë¦¼ |{v:.3f}| (0.5ì—ì„œ ë©€ìˆ˜ë¡ ì ë¦¼)"
            else:
                series = df[real_col]
                signal, score = percentile_signal(series, value, higher_is_risky=meta["higher_is_risky"])
                display_value = f"{value:,.4g}"

            # ì „ì¼ ëŒ€ë¹„
            delta_txt = None
            if prev_row is not None and real_col in prev_row.index:
                pv = prev_row.get(real_col, np.nan)
                if not pd.isna(pv):
                    pv = float(pv)
                    delta = value - pv
                    if k in ["funding", "taker", "m2"]:
                        delta_txt = f"{delta:+.4f}"
                    else:
                        delta_txt = f"{delta:+,.0f}"

            ui_col.metric(meta["title"], display_value, delta=delta_txt)
            ui_col.caption(f"{signal}  Â·  `{real_col}`")
            if extra_line:
                ui_col.caption(extra_line)

            signal_map[k] = signal
            total_score += score
            used += 1

        st.divider()

        avg_score = total_score / max(used, 1)
        st.subheader("ìš”ì•½")
        st.success(overall_risk_text(avg_score))
        st.info(build_cause_summary(signal_map))

        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°(ì»¬ëŸ¼ ì„ íƒ)"):
            all_cols = list(df.columns)
            default_cols = [c for c in ["ret_log_1d", colmap.get("oi"), colmap.get("funding"), colmap.get("liq"), colmap.get("taker"), colmap.get("m2")] if c]
            picked = st.multiselect("í‘œì‹œí•  ì»¬ëŸ¼", options=all_cols, default=default_cols)
            if picked:
                st.dataframe(df[picked].tail(200), use_container_width=True)
            else:
                st.dataframe(df.tail(50), use_container_width=True)

    # ======================
    # Tab 2: Market Mood
    # ======================
    with tab2:
        st.subheader("ğŸ§  Market Mood")
        st.caption("Risk Signal(ì§€í‘œ ì‹ í˜¸ë“±) ì ìˆ˜ë¥¼ â€˜ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´â€™ë¡œ ë²ˆì—­í•œ ìƒíƒœ ì§€í‘œì…ë‹ˆë‹¤.")

        # Risk íƒ­ì—ì„œ ê³„ì‚°í•œ avg_scoreê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ì—¬ê¸°ì„œë„ ì•ˆì „ ê³„ì‚°
        # (ê°™ì€ selected_dateë¥¼ ì¨ì„œ ì¼ê´€ë˜ê²Œ)
        unique_dates = sorted(pd.unique(df.index.date), reverse=True)
        selected_date = st.sidebar.selectbox(
            "Market Mood ê¸°ì¤€ ë‚ ì§œ(ìµœê·¼ì´ ìœ„)",
            options=unique_dates,
            index=0,
            format_func=lambda d: d.strftime("%Y-%m-%d"),
            key="mood_date",
        )
        selected_df = df[df.index.date == selected_date]
        today = selected_df.iloc[-1] if not selected_df.empty else df.iloc[-1]

        # Risk score ì¬ê³„ì‚°(ê°„ë‹¨íˆ ë™ì¼ ë¡œì§)
        colmap2 = {
            "oi": find_column(df, ["oi_close_diff", "oi_diff", "open_interest_diff", "open_interest", "oi"]),
            "funding": find_column(df, ["funding_close", "funding", "funding_rate"]),
            "liq": find_column(df, ["liq_total_usd_diff", "liquidation_usd", "liq_usd", "liq_total_usd"]),
            "taker": find_column(df, ["taker_buy_ratio", "taker_ratio"]),
            "m2": find_column(df, ["global_m2_yoy_diff", "m2_yoy_diff", "global_m2_yoy", "m2_yoy"]),
        }
        indicators2 = {
            "oi": {"higher_is_risky": True},
            "funding": {"higher_is_risky": True},
            "liq": {"higher_is_risky": True},
            "taker": {"higher_is_risky": True},
            "m2": {"higher_is_risky": False},
        }

        total, cnt = 0, 0
        for k, meta in indicators2.items():
            c = colmap2.get(k)
            if not c or c not in df.columns:
                continue
            v = today.get(c, np.nan)
            if pd.isna(v):
                continue
            v = float(v)
            if k == "taker":
                s = (df[c] - 0.5).abs()
                vv = abs(v - 0.5)
                _, sc = percentile_signal(s, vv, higher_is_risky=True)
            else:
                _, sc = percentile_signal(df[c], v, higher_is_risky=meta["higher_is_risky"])
            total += sc
            cnt += 1

        avg = total / max(cnt, 1)
        mood, mood_desc = market_mood_label(avg)

        st.markdown(
            f"""
            ### {mood}

            {mood_desc}

            **(ì°¸ê³ )** Market MoodëŠ” â€˜ê°€ê²© ì˜ˆì¸¡â€™ì´ ì•„ë‹ˆë¼ **í˜„ì¬ ì‹œì¥ì˜ êµ¬ì¡°/ì‹¬ë¦¬ ìƒíƒœë¥¼ ìš”ì•½**í•©ë‹ˆë‹¤.
            """
        )

        st.divider()
        st.write("**êµ¬ê°„ ì•ˆë‚´**")
        st.write("- ğŸ”µ Calm  â†’ ğŸŸ¢ Stable â†’ ğŸŸ¡ Warm â†’ ğŸŸ  Hot â†’ ğŸ”´ Too Hot")

    # ======================
    # Tab 3: VAR Insight
    # ======================
    with tab3:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD(í‘œ)")

        st.sidebar.header("VAR ì„¤ì •")

        all_numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        default_candidates = [c for c in ["ret_log_1d", "oi_close_diff", "funding_close", "liq_total_usd_diff", "taker_buy_ratio", "global_m2_yoy_diff"] if c in df.columns]
        default_sel = default_candidates[:4] if len(default_candidates) >= 2 else all_numeric_cols[:3]

        selected_cols = st.sidebar.multiselect(
            "VAR ë³€ìˆ˜ ì„ íƒ(2ê°œ ì´ìƒ)",
            options=all_numeric_cols,
            default=default_sel,
            key="var_cols",
        )

        if selected_cols:
            target = st.sidebar.selectbox("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜", options=selected_cols, index=0, key="var_target")
            impulse_options = [c for c in selected_cols if c != target]
            impulse_var = st.sidebar.selectbox(
                "IRF Impulse(ì¶©ê²©) ë³€ìˆ˜",
                options=impulse_options if impulse_options else selected_cols,
                index=0,
                key="var_impulse",
            )
        else:
            target, impulse_var = None, None

        lag = st.sidebar.slider("VAR lag", min_value=1, max_value=10, value=1, key="var_lag")
        horizon = st.sidebar.slider("IRF/FEVD horizon", min_value=5, max_value=30, value=10, key="var_h")
        standardize = st.sidebar.checkbox("í‘œì¤€í™”(z-score) í›„ ì í•©", value=True, key="var_z")
        show_full_grid = st.sidebar.checkbox("IRF ì „ì²´ ê·¸ë¦¬ë“œë„ ë³´ê¸°", value=False, key="var_grid")

        run_btn = st.button("VAR ì‹¤í–‰", type="primary")

        if run_btn:
            try:
                with st.spinner("VAR ì í•© ì¤‘â€¦"):
                    out = run_var_bundle(
                        df=df,
                        selected_cols=selected_cols,
                        target=target,
                        lag=lag,
                        horizon=horizon,
                        standardize=standardize,
                    )
                st.session_state["var_out"] = out
                st.session_state["var_params"] = {
                    "target": target,
                    "impulse": impulse_var,
                    "horizon": horizon,
                    "show_full_grid": show_full_grid,
                }
                st.success(f"ì™„ë£Œ! (í•™ìŠµ ë°ì´í„° rows: {out['var_rows']})")
            except Exception as e:
                st.error(f"VAR ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                st.session_state["var_out"] = None
                st.session_state["var_params"] = None

        out = st.session_state.get("var_out")
        params = st.session_state.get("var_params")

        if not out:
            st.info("ì™¼ìª½ì—ì„œ ë³€ìˆ˜ ì„ íƒ í›„ **VAR ì‹¤í–‰**ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            st.stop()

        # 1) Granger
        st.subheader("1) Granger ì¸ê³¼í…ŒìŠ¤íŠ¸ (x â†’ target)")
        st.caption("p-valueê°€ ì‘ì„ìˆ˜ë¡ â€˜xê°€ targetì„ ê·¸ëœì € ì¸ê³¼í•œë‹¤â€™ëŠ” ê·¼ê±°ê°€ ê°•í•©ë‹ˆë‹¤(ê´€í–‰ì ìœ¼ë¡œ 0.05 ê¸°ì¤€).")
        st.dataframe(out["granger_table"], use_container_width=True)

        st.divider()

        # 2) IRF
        st.subheader("2) IRF (Impulse â†’ Target)")
        irf = out["irf"]
        imp = params.get("impulse")
        tgt = params.get("target")

        if imp and tgt:
            fig = irf.plot(impulse=imp, response=tgt)
            fig.set_size_inches(9, 4)
            fig.tight_layout()
            st.pyplot(fig, clear_figure=True)
        else:
            st.warning("IRFë¥¼ ìœ„í•´ impulse/target ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        if params.get("show_full_grid", False):
            st.caption("ì „ì²´ ê·¸ë¦¬ë“œëŠ” ë³€ìˆ˜ê°€ ë§ìœ¼ë©´ ê²¹ì³ ë³´ì¼ ìˆ˜ ìˆì–´ìš”.")
            fig2 = irf.plot()
            fig2.set_size_inches(12, 10)
            fig2.tight_layout()
            st.pyplot(fig2, clear_figure=True)

        st.divider()

        # 3) FEVD
        st.subheader("3) FEVD ë¶„ì‚°ë¶„í•´ (target ê¸°ì¤€)")
        st.caption("ê° horizonì—ì„œ target ë³€ë™ì„ â€˜ì–´ë–¤ shock(ë³€ìˆ˜)ì´ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€(%)â€™")
        st.dataframe(out["fevd_table_target"], use_container_width=True)


if __name__ == "__main__":
    main()
