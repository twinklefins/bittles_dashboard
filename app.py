import math
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from statsmodels.tsa.api import VAR


# ======================
# Paths
# ======================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

DRAFT_PATH = DATA_DIR / "df_draft_1209_w.sti.csv"
VAR_PATH = DATA_DIR / "df_var_1209.csv"


# ======================
# Utils
# ======================
def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None


def safe_to_datetime(s: pd.Series) -> pd.Series:
    return pd.to_datetime(s, errors="coerce", utc=True)


def zscore(series: pd.Series) -> pd.Series:
    x = series.replace([np.inf, -np.inf], np.nan)
    mu = x.mean()
    sd = x.std()
    if sd == 0 or pd.isna(sd):
        return pd.Series(np.nan, index=x.index)
    return (x - mu) / sd


def percentile_signal(series: pd.Series, value: float, higher_is_risky: bool = True) -> Tuple[str, int]:
    """
    Return (emoji, score)
    score: ğŸŸ¢0, ğŸŸ¡1, ğŸ”´2, âšªï¸1
    """
    if series is None or series.empty or pd.isna(value):
        return "âšªï¸", 1

    s = series.replace([np.inf, -np.inf], np.nan).dropna()
    if s.empty:
        return "âšªï¸", 1

    lower, upper = s.quantile([0.33, 0.66])

    if higher_is_risky:
        if value >= upper:
            return "ğŸ”´", 2
        if value <= lower:
            return "ğŸŸ¢", 0
    else:
        if value <= lower:
            return "ğŸ”´", 2
        if value >= upper:
            return "ğŸŸ¢", 0

    return "ğŸŸ¡", 1


def overall_risk_text(total_score: int, count: int) -> str:
    avg = total_score / max(count, 1)
    if avg < 0.5:
        return "ğŸŸ¢ ê³¼ì—´/ì ë¦¼ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. ë‹¨ê¸° ë…¸ì´ì¦ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤."
    if avg < 1.2:
        return "ğŸŸ¡ ë‹¨ê¸° ë³€ë™ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. íŒ¨ë‹‰ì…€ë³´ë‹¤ëŠ” ì›ì¸(ë ˆë²„ë¦¬ì§€/ì ë¦¼/ìœ ë™ì„±)ì„ ë¨¼ì € ì ê²€í•˜ì„¸ìš”."
    if avg < 1.8:
        return "ğŸŸ  ë ˆë²„ë¦¬ì§€Â·ì ë¦¼ ì‹ í˜¸ê°€ ê´€ì¸¡ë©ë‹ˆë‹¤. í¬ì§€ì…˜ í¬ê¸°/ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    return "ğŸ”´ ë‹¨ê¸° ì¶©ê²©(ê°•ì œì²­ì‚°/ì ë¦¼) ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¬´ë¦¬í•œ ë ˆë²„ë¦¬ì§€ëŠ” í”¼í•˜ì„¸ìš”."


# ======================
# CII (optional)
# ======================
def build_cii(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    # âœ… ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼ëª… â†” ì½”ë“œì—ì„œ ì“°ê³  ì‹¶ì€ ë…¼ë¦¬ëª… ë§¤í•‘
    alias = {
        "gt_bitcoin": ["gt_bitcoin", "bitcoin", "gtrend_bitcoin"],
        "gt_btc_z14": ["gt_btc_z14", "gtrend_btc_z14", "gt_btc_z14"],
        "rd_avg_sent": ["rd_avg_sent", "avg_sent", "reddit_avg_sent"],
        "rd_pos_ratio": ["rd_pos_ratio", "pos_ratio"],
        "rd_neg_ratio": ["rd_neg_ratio", "neg_ratio"],
        "rd_rolling_mean_neg": ["rd_rolling_mean_neg", "rolling_mean_neg"],
        "rd_rolling_std_neg": ["rd_rolling_std_neg", "rolling_std_neg"],
        "rd_count": ["rd_count", "count", "rd_cnt"],
    }

    def pick(name: str) -> Optional[str]:
        for c in alias[name]:
            if c in out.columns:
                return c
        return None

    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ìœ¼ë¡œ resolve
    col = {k: pick(k) for k in alias.keys()}

    missing = [k for k, v in col.items() if v is None]
    if missing:
        out["CII"] = np.nan
        # ë””ë²„ê¹…ìš©: ì–´ë–¤ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸
        out.attrs["cii_missing"] = missing
        out.attrs["cii_colmap"] = col
        return out

    # ---- ê³„ì‚° ----
    out["rd_pos_minus_neg"] = out[col["rd_pos_ratio"]] - out[col["rd_neg_ratio"]]

    out["cii_attention"] = (z(out[col["gt_bitcoin"]]) + z(out[col["gt_btc_z14"]])) / 2
    out["cii_sentiment"] = (
        z(out[col["rd_avg_sent"]]) +
        z(out["rd_pos_minus_neg"]) -
        z(out[col["rd_rolling_mean_neg"]])
    ) / 3
    out["cii_volatility"] = (
        z(out[col["rd_rolling_std_neg"]]) +
        z(out[col["rd_count"]])
    ) / 2

    out["CII"] = (
        0.4 * out["cii_attention"] +
        0.4 * out["cii_sentiment"] +
        0.2 * out["cii_volatility"]
    )

    out.attrs["cii_missing"] = []
    out.attrs["cii_colmap"] = col
    return out


# ======================
# Data loader
# ======================
@st.cache_data(show_spinner=False)
def load_data() -> Tuple[pd.DataFrame, str]:
    """
    draft ìš°ì„  ë¡œë“œ, ì—†ìœ¼ë©´ var ë¡œë“œ.
    return (df, source_name)
    """
    if DRAFT_PATH.exists():
        path = DRAFT_PATH
        source = "df_draft_1209_w.sti.csv"
    elif VAR_PATH.exists():
        path = VAR_PATH
        source = "df_var_1209.csv"
    else:
        return pd.DataFrame(), "NO_FILE"

    df = pd.read_csv(path)

    if "time" not in df.columns:
        raise ValueError("CSVì— 'time' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["time"] = safe_to_datetime(df["time"])
    df = df.dropna(subset=["time"]).set_index("time").sort_index()

    # CII ì‹œë„(ì—†ìœ¼ë©´ ìë™ NaN)
    df = build_cii(df)

    return df, source


# ======================
# VAR helpers
# ======================
def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    std = df.std().replace(0, np.nan)
    return (df - df.mean()) / std


def run_var_bundle(
    df: pd.DataFrame,
    selected_cols: List[str],
    target: str,
    lag: int,
    horizon: int,
    standardize: bool,
) -> Dict[str, object]:
    if len(selected_cols) < 2:
        raise ValueError("VAR ë³€ìˆ˜ëŠ” 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    if target not in selected_cols:
        raise ValueError("íƒ€ê²Ÿ(ë°˜ì‘) ë³€ìˆ˜ëŠ” ì„ íƒëœ VAR ë³€ìˆ˜ ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    data = df[selected_cols].replace([np.inf, -np.inf], np.nan).dropna()
    if data.shape[0] < max(60, lag * 12):
        raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (rows={data.shape[0]}). lag={lag}ë©´ ìµœì†Œ 60í–‰ ì´ìƒ ê¶Œì¥")

    if standardize:
        data = zscore_df(data).dropna()

    res = VAR(data).fit(lag)

    # Granger: x -> target
    rows = []
    for x in selected_cols:
        if x == target:
            continue
        try:
            test = res.test_causality(caused=target, causing=[x], kind="f")
            rows.append({
                "causing(x)": x,
                "caused(target)": target,
                "stat": float(test.test_statistic),
                "pvalue": float(test.pvalue),
            })
        except Exception as e:
            rows.append({
                "causing(x)": x,
                "caused(target)": target,
                "stat": np.nan,
                "pvalue": np.nan,
                "error": str(e),
            })
    granger = pd.DataFrame(rows).sort_values("pvalue", na_position="last").reset_index(drop=True)

    # IRF
    irf = res.irf(horizon)

    # FEVD (shape ë°©ì–´)
    fevd = res.fevd(horizon)
    decomp = np.array(fevd.decomp)  # (steps, response, impulse)
    names = list(res.names)
    t_idx = names.index(target)

    # step0 í¬í•¨ ì—¬ë¶€ ì²˜ë¦¬
    if decomp.shape[0] == horizon + 1:
        use = decomp[1:, t_idx, :]   # (horizon, impulse)
        idx = list(range(1, horizon + 1))
    else:
        use = decomp[:, t_idx, :]
        idx = list(range(1, decomp.shape[0] + 1))

    fevd_tbl = pd.DataFrame((use * 100.0), columns=names, index=idx).round(2)
    fevd_tbl.index.name = "horizon(step)"

    return {
        "granger": granger,
        "irf": irf,
        "fevd": fevd_tbl,
        "rows": int(data.shape[0]),
        "names": names,
    }


# ======================
# App
# ======================
def main():
    st.set_page_config(page_title="ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

    st.markdown(
        """
        <style>
        .block-container { padding-top: 1.2rem; padding-bottom: 2rem; }
        [data-testid="stMetricLabel"] { white-space: normal; font-size: 0.9rem; }
        [data-testid="stMetricValue"] { font-size: 1.55rem; }
        section[data-testid="stSidebar"] .block-container { padding-top: 1.1rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("ğŸ“Š ì‹œì¥ ìœ„í—˜ë„ ëŒ€ì‹œë³´ë“œ")
    st.caption("Risk Signal(ì‹ í˜¸ë“±) + VAR Insight(Granger/IRF/FEVD) + Pipeline")

    df, source = load_data()
    if df.empty:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. repoì˜ data/ í´ë”ì— CSVê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.info("í•„ìš” íŒŒì¼: data/df_draft_1209_w.sti.csv ë˜ëŠ” data/df_var_1209.csv")
        return

    with st.expander("âœ… ë°ì´í„° ë¡œë“œ ì •ë³´(ë””ë²„ê¹…)"):
        st.write(f"source: **{source}**")
        st.write(f"rows: **{len(df):,}**, cols: **{len(df.columns):,}**")
        st.write("columns sample:", list(df.columns)[:30])

    tab1, tab2, tab3 = st.tabs(["ğŸš¦ Risk Signal", "ğŸ§© VAR Insight", "ğŸ§­ Pipeline"])

    # ======================
    # Sidebar: ê³µìš© ì„¤ì • (ë‚ ì§œ)
    # ======================
    st.sidebar.header("ì„¤ì •")
    unique_dates = sorted(pd.unique(df.index.date), reverse=True)  # âœ… ë‚´ë¦¼ì°¨ìˆœ
    sel_date = st.sidebar.selectbox(
        "ê¸°ì¤€ ë‚ ì§œ",
        options=unique_dates,
        index=0,
        format_func=lambda d: d.strftime("%Y-%m-%d"),
        key="base_date",
    )

    # í•´ë‹¹ ë‚ ì§œ ë§ˆì§€ë§‰ row
    day_df = df[df.index.date == sel_date]
    if day_df.empty:
        day_df = df
    latest_row = day_df.iloc[-1]

    # ì „ì¼(ë°”ë¡œ ë‹¤ìŒ ë‚ ì§œê°€ ì „ì¼) row
    idx = unique_dates.index(sel_date)
    prev_row = None
    if idx + 1 < len(unique_dates):
        prev_date = unique_dates[idx + 1]
        prev_df = df[df.index.date == prev_date]
        if not prev_df.empty:
            prev_row = prev_df.iloc[-1]

    # ======================
    # TAB 1: Risk Signal
    # ======================
    with tab1:
        st.subheader(f"ê¸°ì¤€ ë°ì´í„° ë‚ ì§œ: {latest_row.name:%Y-%m-%d}")

        # âœ… ë°ì´í„° ìŠ¤í‚¤ë§ˆê°€ ë‹¬ë¼ë„ ìë™ìœ¼ë¡œ ì»¬ëŸ¼ ì°¾ê¸°
        col_oi = find_column(df, ["oi_close_diff", "oi_close", "open_interest", "oi"])
        col_funding = find_column(df, ["funding_close", "funding_rate", "funding"])
        col_liq = find_column(df, ["liq_total_usd_diff", "liq_total_usd", "liquidation_usd", "liq_usd"])
        col_taker = find_column(df, ["taker_buy_ratio", "taker_ratio"])
        col_m2 = find_column(df, ["global_m2_yoy_diff", "global_m2_yoy", "m2_yoy_diff", "m2_yoy"])

        indicators = [
            ("OI", col_oi, True, "level_or_diff"),
            ("í€ë”©ë¹„", col_funding, True, "level"),
            ("ì²­ì‚°(USD)", col_liq, True, "level_or_diff"),
            ("í…Œì´ì»¤ ë¹„ì¤‘(ì ë¦¼)", col_taker, True, "taker"),
            ("M2", col_m2, False, "level_or_diff"),
        ]

        cols = st.columns(len(indicators), gap="large")
        total_score, used = 0, 0

        for ui_col, (label, colname, higher_is_risky, mode) in zip(cols, indicators):
            if colname is None or colname not in df.columns:
                ui_col.metric(label, "N/A")
                ui_col.caption("âšªï¸ ì»¬ëŸ¼ ì—†ìŒ")
                continue

            v = latest_row[colname]
            if pd.isna(v):
                ui_col.metric(label, "N/A")
                ui_col.caption("âšªï¸ ê²°ì¸¡")
                continue

            # signal ê³„ì‚°
            extra = ""
            if mode == "taker":
                # 0.5ì—ì„œ ë©€ìˆ˜ë¡ ì ë¦¼
                series = (df[colname] - 0.5).abs()
                val = float(abs(v - 0.5))
                signal, score = percentile_signal(series, val, higher_is_risky=True)
                display_value = f"{float(v):.3f}"
                extra = f"ì ë¦¼ |x-0.5| = {val:.3f}"
            else:
                series = df[colname]
                signal, score = percentile_signal(series, float(v), higher_is_risky=higher_is_risky)
                display_value = f"{float(v):,.4g}"

            # delta (ì „ì¼ ëŒ€ë¹„)
            delta_txt = None
            if prev_row is not None and colname in prev_row.index and not pd.isna(prev_row[colname]):
                dv = float(v) - float(prev_row[colname])
                # funding/taker/m2ëŠ” ì†Œìˆ˜
                if colname in [col_funding, col_taker, col_m2]:
                    delta_txt = f"{dv:+.4f}"
                else:
                    delta_txt = f"{dv:+,.0f}"

            ui_col.metric(label, display_value, delta=delta_txt)
            ui_col.caption(f"ì‹ í˜¸: {signal}  Â·  ì»¬ëŸ¼: `{colname}`")
            if extra:
                ui_col.caption(extra)

            total_score += score
            used += 1

        st.divider()
        st.subheader("ì‹ í˜¸ë“± ìš”ì•½")
        st.write("ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ì¤‘ê°„ | ğŸ”´ ë†’ìŒ | âšªï¸ ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡/ì»¬ëŸ¼ ì—†ìŒ")
        st.success(overall_risk_text(total_score, used))

        st.subheader("ğŸ“ˆ ì†Œë¹„ì íˆ¬ì ì¸ë±ìŠ¤ (CII)")
        if "CII" not in df.columns or df["CII"].dropna().empty:
            st.warning("CII ê³„ì‚° ë¶ˆê°€ (í•„ìš” ì»¬ëŸ¼ ë¶€ì¡±)")
        else:
            st.metric("CII (latest)", f"{df['CII'].iloc[-1]:.2f}")
            st.line_chart(df["CII"].tail(200))

        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ê°€ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥)"):
            st.caption("í‘œ ë‚´ë¶€ì—ì„œ ê°€ë¡œ ìŠ¤í¬ë¡¤í•˜ë©´ ëª¨ë“  ì»¬ëŸ¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.dataframe(df.tail(50), use_container_width=True)

    # ======================
    # TAB 2: VAR Insight
    # ======================
    with tab2:
        st.subheader("ğŸ§© VAR Insight")
        st.caption("Granger(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD(í‘œ)")

        st.sidebar.header("VAR ì„¤ì •")

        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        # ê¸°ë³¸ ì¶”ì²œ: ret_log_1d, funding_close, taker_buy_ratio ë“± (ìˆìœ¼ë©´)
        default_candidates = [c for c in ["ret_log_1d", "funding_close", "taker_buy_ratio", "oi_close", "spot_volume_usd", "price_close"] if c in numeric_cols]
        default_sel = default_candidates[:4] if len(default_candidates) >= 2 else numeric_cols[:4]

        selected_cols = st.sidebar.multiselect(
            "VAR ë³€ìˆ˜(2ê°œ ì´ìƒ)",
            options=numeric_cols,
            default=default_sel,
            key="var_cols",
        )

        if selected_cols:
            target = st.sidebar.selectbox("Target(ë°˜ì‘)", options=selected_cols, index=0, key="var_target")
            impulse_opts = [c for c in selected_cols if c != target]
            impulse = st.sidebar.selectbox("Impulse(ì¶©ê²©)", options=impulse_opts, index=0 if impulse_opts else 0, key="var_impulse")
        else:
            target, impulse = None, None

        lag = st.sidebar.slider("lag", 1, 10, 1, key="var_lag")
        horizon = st.sidebar.slider("horizon", 5, 30, 10, key="var_h")
        standardize = st.sidebar.checkbox("z-score í‘œì¤€í™”", True, key="var_z")
        show_grid = st.sidebar.checkbox("IRF ì „ì²´ ê·¸ë¦¬ë“œ(ì˜µì…˜)", False, key="var_grid")

        run_btn = st.button("VAR ì‹¤í–‰", type="primary")

        if "var_out" not in st.session_state:
            st.session_state["var_out"] = None
            st.session_state["var_params"] = None

        if run_btn:
            try:
                with st.spinner("VAR ì í•© ì¤‘â€¦"):
                    out = run_var_bundle(df, selected_cols, target, lag, horizon, standardize)
                st.session_state["var_out"] = out
                st.session_state["var_params"] = {
                    "target": target,
                    "impulse": impulse,
                    "horizon": horizon,
                    "show_grid": show_grid,
                }
                st.success(f"ì™„ë£Œ! (í•™ìŠµ rows: {out['rows']})")
            except Exception as e:
                st.error(f"VAR ì‹¤íŒ¨: {e}")
                st.session_state["var_out"] = None
                st.session_state["var_params"] = None

        out = st.session_state.get("var_out")
        params = st.session_state.get("var_params")

        if out is None:
            st.info("ì™¼ìª½ì—ì„œ ë³€ìˆ˜ ì„ íƒ í›„ **VAR ì‹¤í–‰**ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            st.subheader("1) Granger ì¸ê³¼í…ŒìŠ¤íŠ¸ (x â†’ target)")
            st.caption("p-valueê°€ ì‘ì„ìˆ˜ë¡ â€˜xê°€ targetì„ ê·¸ëœì € ì¸ê³¼í•œë‹¤â€™ëŠ” ê·¼ê±°ê°€ ê°•í•©ë‹ˆë‹¤(ë³´í†µ 0.05 ê¸°ì¤€).")
            st.dataframe(out["granger"], use_container_width=True)

            st.divider()

            st.subheader("2) IRF (Impulse Response)")
            st.caption("ë°œí‘œìš©ìœ¼ë¡œëŠ” impulse 1ê°œ â†’ target 1ê°œë§Œ í¬ê²Œ ë³´ì—¬ì£¼ëŠ” ê²Œ ê°€ì¥ ì½ê¸° ì¢‹ì•„ìš”.")
            irf = out["irf"]
            tgt = params["target"]
            imp = params["impulse"]

            if imp is None or tgt is None:
                st.warning("Impulse/Target ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                fig = irf.plot(impulse=imp, response=tgt)
                fig.set_size_inches(10, 4)
                fig.tight_layout()
                st.pyplot(fig, clear_figure=True)

                if params.get("show_grid"):
                    st.caption("ì „ì²´ ê·¸ë¦¬ë“œëŠ” ë³€ìˆ˜ ë§ìœ¼ë©´ ê²¹ì³ ë³´ì¼ ìˆ˜ ìˆì–´ìš”.")
                    fig2 = irf.plot()
                    fig2.set_size_inches(12, 10)
                    fig2.tight_layout()
                    st.pyplot(fig2, clear_figure=True)

            st.divider()

            st.subheader("3) FEVD ë¶„ì‚°ë¶„í•´ (target ê¸°ì¤€)")
            st.caption("ê° horizonì—ì„œ target ë³€ë™ì„ â€˜ì–´ë–¤ shock(ë³€ìˆ˜)ì´ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€(%)â€™ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            st.dataframe(out["fevd"], use_container_width=True)

    # ======================
    # TAB 3: Pipeline
    # ======================
    with tab3:
        st.subheader("ğŸ§­ ë¶„ì„ íŒŒì´í”„ë¼ì¸")
        st.markdown(
            f"""
1. **ë°ì´í„° ë¡œë“œ**
   - ìš°ì„ : `data/df_draft_1209_w.sti.csv`
   - ì—†ìœ¼ë©´: `data/df_var_1209.csv`
   - í˜„ì¬ ë¡œë“œ ì†ŒìŠ¤: **{source}**

2. **Risk Signal**
   - ë°ì´í„° ìŠ¤í‚¤ë§ˆê°€ ë‹¬ë¼ë„ ìë™ìœ¼ë¡œ ì»¬ëŸ¼ í›„ë³´ë¥¼ íƒìƒ‰í•´ ì‹ í˜¸ë“± ìƒì„±
   - í…Œì´ì»¤ ë¹„ì¤‘ì€ `|taker_buy_ratio - 0.5|`ë¡œ ì ë¦¼ ê³„ì‚°

3. **(ì˜µì…˜) CII**
   - GT/Reddit ê´€ë ¨ ì»¬ëŸ¼ì´ ì¡´ì¬í•  ë•Œë§Œ CII ê³„ì‚° ë° ì‹œê°í™”

4. **VAR Insight**
   - VAR ì í•© â†’ **Granger(í‘œ) / IRF(ê·¸ë˜í”„) / FEVD(í‘œ)**
"""
        )


if __name__ == "__main__":
    main()
